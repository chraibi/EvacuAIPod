 Hello everybody, welcome to the Fire Science Show. In today's episode I have for you some fire modeling. Probably you're wondering why we're always doing fire modeling in this show, but today I really mean it. This is an episode about what you need to do to truly model fire. And I've invited a guest, Professor Lucas Arnold from University of Wuppertal and the Jülich Forschungszentrum, who is developing interesting approaches to modeling simple materials and in future more complicated materials for the fire safety in the railway industry. And in this episode, we're going to talk about what it takes to truly model the fire behavior of a material and how these approaches, the properties of materials, the things that really matter change when you think about different scales at which you model this behavior. Very interesting, perhaps on the difficult side, the episode is certainly not easy, despite the fact that I'm having a fire laboratory even for me. It was difficult at some parts because we're going quite deep into the modeling aspects, but I've decided we need to show it like it is because people need to understand how challenging and difficult this approach to truly model fire is. So I hope you'll find it inspiring, interesting, and if you happen to be a researcher who is also working on modeling fires, I am absolutely sure this episode will be a goldmine of knowledge and inspiration for you. So without further ado, let's spin the intro and jump into the episode. Welcome to the Firesize Show. My name is Wojciech Wigrzyński and I will be your host. Firesize Show is produced in partnership with OFAR Consultants, a multi-award winning independent consultancy dedicated to addressing fire safety challenges. OFAR is the UK's leading fire risk consultancy with a globally established team. I've just learned that OFAR won the Small and Medium Enterprise of the Year Award in the 2023 Engineering Talent Award. I've met a lot of OFAR's talent and I understand why this award went to them. So, huge congratulations to the OFR. Very well-deserved award. And if you are a talent that would like to join such an esteemed team, OFR is always looking to hear from industry professionals who would like to collaborate. Get in touch at OFRConsultants.com. Hello, everybody. Welcome to the Fire Science Show. I'm joined today by Professor Lukas Arnold. Hello, Lukas. Hi, Wojciech. Good to see you again in the show. We've talked a lot about modeling stuff in computers, and I know that you have some very nice, interesting developments in the field of modeling fires related to railway fire safety in your project, Baskett. I love the name, by the way. So I would love to pick your brain on how are we modeling fire spread, fires, fire kinetics, and what does that mean for fire safety engineering overall? I guess we'll take a deep dive into modeling, but first let's hear about the context. So why your research interests have focused on modeling how things burn in the railway context? So first of all, Wojciech, thanks again for having me here. And I think many of the audience doesn't know what Pesquite means because I think this is our joint route uh what you're right so that's why you find it funny but for most of them no um so this is a region in south of poland just before the tatra mountains this is a very nice hilly region where we are both born right yeah you're also 50 50 kilometers away. Yeah, so, and then you know how acronyms work. If you think of a nice name and then come up with a long version of that. So the idea in the BASCID project is to move forward to the field of pyrostrate modeling. And the context, as you said, is the trains. And this is due to the fact that we have in Germany funding options to do research, safety research, that needs to benefit the society. So in our case, it's to make trains safer or do the process more efficient to make trains safer. So that's why we teamed up with two companies, one BCL from Leipzig and two Züht Rail. So the guys that we work with are situated in Berlin, I think the main headquarters in Munich, and they both work exactly on that field. So they work on the safety of trains, means regional regional national trains but also trams so everything that is and the intercity trains as well or just original so in general i would say they work on all these kind of uh trains and they run simulations okay okay so that's why we teamed up so they they use, of course, different approaches to predict fires, and especially fire spread in trains. So they are very interested in having new models, eventually faster models, to come up with design fires that then can be used to outline station safety and so on. But we, as researchers, and by we I mean, and this is Fabian Plünscher from the University of Wuppertal, Alexander Bell from Aachen, and me from Jülich and from Aachen, that we come up with new approaches, new experiments, to help these guys to work on that. Of course, it's always, everything that we do is open access, so we're not doing this work only for them. We team up to the process, but everything is freely available. Come on, isn't it simple? You just take the polyurethane foam from FDS4 material base, you put it in your model, you set up ignition temperature, and you have flame spread. What's more there to research? Everyone's doing that. No, just kidding. No, I mean, this is true because in the end, the question is how well does it fit reality or not? So if you don't check, then you will not know. You will get an answer, like with all the modern tools. If you don't manage to crash FBS, which is not so easy to do, then you will get an answer. The question is how valid it is and the role of the scientist and the engineer is to judge on that. I mean, that's the idea of an endeavor that you have also had in your podcast about the MacFB where people team up, many people team up to understand fire growth, fire spread of DMMA. So it means like without going to lead it, it obviously is a challenge. So you cannot just use these parameters and it's going to work. And there are really various reasons for that, that it's not working. So by it isn't working, you mean just taking some known properties of the material, putting them in a software like FDS and expecting that the real scale will match the reality. That's the part that doesn't work. Like you get some reason, but it's not exactly the real or the true fire that you would get from it. Yeah, but I mean, it's good to point that out. you would get from it. Yeah, but I mean, it's good to point that out. So what I meant in my head was you look up literature values, as you said, put it into a fire model like FDS, do a flame spread, and then compare it to an experiment that you have modeled, a real scale experiment. And then you would compare different properties, heat release rates, mass release rates, maybe on some velocity fields and whatnot, or temperatures of the solid. And I would say in general, that's not going to work this way. Okay. But you need to check. And the challenge here is, and this is also what in my impression, we are also facing, that we need to be able to model the real scale also. So what we focus on is mostly the pyrolysis, so the solid phase of the fire propagation process. But once you have a large scale experiment, the gas phase is also very important. So what is the erodited fraction of your fuel that you don't know? So you come up with surrogates, even if we may name them methane or whatever. This is, in reality, probably just a surrogate. So we don't know these properties. And in a large fire, you need to do the interaction of the gas phase and your solid and the overall geometry right to judge whether your predictions based on your material parameters are correct or not. Okay, so everything can match the experimental data, maybe due to the fact that your material parameters are wrong, and your numerical model is also not correct. Okay, and then by chance, it works out. I think that's a challenge. And it's a challenge to run large-scale experiments in a lab. So therefore, I think it is very, very important to have reproductions of experiments. I mean, this is the goal also of MEC-FP, where different laboratories tested or examined the same material. That's very good. It works out nicely on the microgram scaler. But when it comes to the real-scale experiments, that's something that we need to do as well. Okay, so different labs, different environmental conditions, and so on, because then it's still hard to judge, like, is my heat release rate curve off because something happened in the experiment, or is it off because my parameters are wrong? And therefore, i think we we need to have a more extensive experimental database on real scale and even do the same experiments it seems boring and i know it's hard to sell to people giving out money but there would be in my opinion a huge value to have the same experiments run by different groups we'll come back to going across the scales because it's also something fascinating and very unique to the research you're doing. And I absolutely love the approach. But to close on the context, I think the train context is very nice to have this discussion. When do we really need as engineers the capability of flames? You know, because we are very based in the paradigm of design fires. You take a design fire, you put it inside a room, compartment, railway cart even. And if you have a design fire that has predetermined the release of heat, release of smoke, release of toxic pollutants, there is nothing in kinetics to model in that. You simply want to release this amount of outcomes of the chemical reactions into your environment. Though, also working in this field, especially when you work in experiments, in large-scale experiments, you really see the variability of those fires. Like, if you burn cribs under the hood, freestanding, on the ground, you have 20 cribs, you burn them the same way, they're going to burn more or less in the same way. There will be some discrepancies between one test and another, but in general, it's going to be the same fire. But if you place it in a small room, in a large room, in a train, against a wall, it's going to be completely different fires. And I feel that this design fire paradigm becomes at some point very hard to justify, especially in small spaces where the flows will very much define where the fire can be and how can it grow. How can it grow? So if you had a model that instead of placing a heat source inside a mock-up train, if you could model luggage, seats, floor, cables, whatever is there that's combustible, trigger the fire and see how it spreads through the cart, giving you an outcome in terms of the design fire, that would be a huge, huge improvement because there are so many factors that affect that. Yes, that's the vision that I have. So my background is theoretical physics, so I lived in a different world. But when you start to build something or evaluate the safety, then you need to have faculty approaches. So the design fire is one of them. So it's a good tool. However, I think with increased computing capabilities and so on, we can move forward to tackle the fact that the design fire is really just an approximation, a crude one. I think Jose once said that the design fire is an outcome, not an input, in a way. And I think that thought is beautiful in this context. Yes, that's true. And what I envision, like what the contribution of some of the scientific effort should be is make these tools also available for engineering so that they run faster than now. That you can come up with material parameters. I mean, that's a big topic, how to determine them at all, that you come up quickly with the material parameters that you need, and that you will gain the opportunities that you outlined already. The design fire will be different if you place your fire somewhere else. But especially when you want to investigate what are the safety measures like sprinklers or water mist or whatever, without predicting the outcome of its impact so that you can evaluate different designs, different setups, whatnot, then you need to have a model that really interacts with its environment. A design fire is basically a textbook, so like a screenplay, it's already written down what will happen. In the other case, there is interaction, okay, so that you can really evaluate how good is my safety measure performing or not. You brought up a very difficult discussion that we very often have, especially in context of shopping malls, where you have design fires for sprinklers versus unsprinkled shops, and we're often asked, like, how do you account for sprinklers? And we're like, the only way I can do this is by cutting the design fire down. And then the question is, but your smoke is like 200 degrees, and yeah, because there's nothing to cool it. That's how it ends up. Now people would take a design fire and then put sprinklers in the model to cool down the fire. And for me, this is like artificial because there is interaction with the fuel, with the fire. Like, you either are solving fire physics or you are substituting this fire with a surrogate design fire with all consequences of that substitution. Like, it's a process, it's a test. I usually brought a comparison to fire testing, fire resistance testing. Everyone knows that the standard fire test is not a real representation of a fire, but it doesn't stop us from comparing hundreds of different types of solutions with a known benchmark to have some insight in how they behave in fires. We know it's not the reality, but it's still useful. In the same way, CFD or any other analysis with a design fire is useful because you can benchmark your building against this test, which is the design fire. But you're nowhere close solving physics. You're nowhere close to simulating a real fire even. You're literally testing a building or its systems against a known emission of heat and smoke. And having the ability to really account for the spread and the even more fantastic things that you mentioned, suppression, reactions between those, perhaps even more complicated flames, but perhaps transition into flashover or some more complex phenomena. I think this would be a whole new world for fire engineering. I wonder how many people would like it, because the word gives a living hood for many people, and it's quite convenient. But for me as a scientist, that would be fascinating to have models for which I could really trust and say that I'm really sure that what I'm modeling is close to reality. So I think what we do in research is one thing, but what we provide for engineering, if I may do this distinction, is just another tool. Okay. So it's up to every engineer which tool she or he is using. And that's absolutely fine. I think that hand calculations are great. Okay, so everybody understands it, but you need to know the limits as with all the models. And if you think that none of the models are applicable, but the super extensive one and it's worse for the project, then I hope that there will be eventually at one time a tool that you can use to do that. And you can derive with this one many submodels. Okay a tool that you can use to do that. And you can derive with this one many sub-models, okay, so that you don't have to run the complex things all over again. So let's try, how does a scientist find an answer to how to model behavior of materials in full scale in relation to flame spread? Because I think flame spread is the most important thing that we would be interested in if you want a real fire growth simulation. So what tools do you have access to? Like, what's the scales that you can work at? I think there are many approaches to deal with that. One that is often used recently is that you rely on different scales of experiments. So you start with a micro-scale, scalar, which means that you do a TGA, demographic analysis, an MCC, microcombustion colorimeter, which are all samples, well, a few milligrams. Having that data, you can investigate the process and the heat of combustion, for example. Okay, so these devices don't provide you the values for your reaction rates. It's, for example, the mass loss rate. But you can then apply models to find out what would be the reaction rates, for example, find out what would be the reaction rates, for example, the A's and E's of an erroneous approach to prescribe what the apparatus did measure. I always like to have calorimetry as my sanity check, you know, the upper bound of energy release. You know, you're not going to have more energy release from your material than you had in oxygen calorimetry in a bomb, right? You know, as a sanity check. If my model goes beyond that, that means it's impossible. And TGA, perhaps to some extent, you can have a sanity check on what temperature-specific things are happening. Because if I correctly understand the method, you do some stuff along temperature growth. So if you know that some stuff is happening at 200 and your model would show it at 100, it's also like a sanity check. It's not going to happen. However, I find this bounce interesting and useful as bounce. They're not answers to questions, you know, why and how things are progressing. That's how I understand these methods because I really like working on this microscale. It's convenient. Yeah, so it is eventually. Also, when you look at the details, things become also more difficult, the easiest scale. So you assume that everything is isothermal, there are no transfer, or the transfer processes are way faster than the scale at which you increase the temperature. So this is already a simple setup. So it's a zero dimensional thing, basically. So having then the kinetics of your pyrosis, you can move forward to the next scalar, which would be, for example, the gasification apparatus or a cone color meter. A gasification apparatus is taking samples of roughly just order of magnitude, 10 by 10 centimeters or 10 centimeters, let's stick with one direction. And what it does is it irradiates the sample like the cone colorimeter, probably many people know the sample in a inert atmosphere, so mostly nitrogen. So what you measure is there are no flames, obviously, because there's no oxygen. What you measure is the mass loss of your sample, as it gasifies. You can do the same thing with a conchalometer, where obviously there is oxygen, and we'll have then a fire so that you can measure the mass loss, but also the energy release. And these are the quantities that these apparatus provide to you besides others. But the main ones is, for example, the mass and the energy release rate. And then you do the same thing that you come up with your fire model. Now it needs to be more complex because you have the heat transfer in the sample. You've got the porosis with the parameters that you may have estimated from the micro scale experiment. And if you do a conch odometer, you eventually have to, in my opinion, include the gas phase so that you have also the heat feedback from the flame. And then you use this model to come up with model parameters for the thermophysical parameters. the thermophysical parameters. So if everything works out, you would have then a set of parameters that you would need to prescribe the flame spread, so all these parameters, and heat conduction, heat capacity, and so on of the sample. Of course, these numbers are not just numbers, but that the heat capacity and heat conduction and so on of a sample is temperature. Okay, so these are not individual values, but actually functions of temperature. So we typically approximate them with a few points, but you need to take that into account and you can assume that the material keeps its properties. I think this scale is a dream of many people. So if you could, you know, just run a cone test on a material and then have a complete knowledge on the behavior of the material. At this scale, as you mentioned, having into account some heat transfer and some other material-specific properties, it would be fantastic if you could just run a cone and, you know, you have a working CFD model. But I don't feel that's reality. I know a lot of people are trying that. I think it's but maybe I'm overestimating what we in the community can do but I wouldn't say that doesn't make sense. Maybe we get there. That you do one cone test. Not one. You would have to repeat it maybe. You would just use one tool, a cone? Yes, exactly, in a meaningful way. And then to come up with all the parameters that you need. I think it's not easy, and maybe we are not there yet, but maybe that's doable. I know there were efforts. In a way, we turned the room corner test into SBI test at some point of the history of humanity, which justifies an episode on just that. And I'll deliver that one day. And I know there's efforts to, you know, predict SBI with a code. So there is, you know, a relation overall. If you can predict SBI, it kind of means you predicted the flashover in room corner test. So it is, in a way, prediction of the very large scale behavior with a very small method, because you perhaps get most of the important elements out of it. But again, if you're talking about cone, you're not just talking about take one sample, 50 kilowatts, burn it down, you know, everything. It's more than that. It's multiple repetition. It would be multiple irradiations, right? Yes, that would be part of it these two um have also check your model whether it works which should then work for different irradiations okay so once you have the model or material parameter fixed it should work also for the other uh so it's for sure helpful if it's not even needed to have that. But right now, we use one or few of them to come up with the material parameters. And what one needs to know is that with this approach, I mean, the model of the cone colorimeter and the sample, it's very simple. And we cannot do the assumptions that we did on the small scale, like that everything is basically zero dimensional. So it's like a super small sample. So if you go to the eventually simplest material, PMMA, that we hope that is the easiest to grab. And if you have a look on that, maybe you can add it into your podcast, you can see bubbles. You cannot see them, but you can hear them. So there is a bubbling layer on top of your sample while it's irradiated. You really hear it cooking. That's something that we don't have in our model, that there was a bubble layer on top, which obviously has different material properties than the solid, for obvious reasons. But it strongly interacts with the heat transfer and mass transfer processes, and radiation is also playing a good part. So, we have a set of parameters that describes this process, but we have to take care about saying, like, these are the parameters that are the properties of the PMMA. No, it's of the system itself, like having this layer of bubbles on top of that. If you think about wood or timber that creates tracks and so on, that's something you cannot kind of cover, not yet at least. So the set of parameters that you have is an effective one that represents these behaviors, okay, which is in a sense fine because this is what's going to happen later on. And it depends as always on the scale that you look at. Okay, so we've got also other processes where we know if we zoom in, they are completely different, but we come up with a model to describe what is happening. So it's fine to have these parameters, even if we know that they are not the true one. A typical example for that, you as a CFD person know, is Turbulence model. So the Turbulent Viscosity, well, that's an artificial parameter. Yes. If you would zoom in and really resolve the eddies and the dissipation of the eddies, go to the Kolmogorov scale and make it even finer, then you wouldn't need it. But you say, okay, I cannot go down to that. And I describe the effects of this dissipation and so on via a larger scale process, viscosity in that case, to describe what is going on on the smaller scale. This is a really great example because in turbulence modeling, you can go literally with two equation models and just calculate the viscosity. You can go Reynolds stress model where you would assume it's not the same in every direction so you start to input the directional stuff in it. You solve it for every direction separately and you could go into large eddy simulation where you assume that for large eddies you solve them for small eddies it's average and you could go DNS where you just model everything up to the tiniest little element that's physically possible. In the end, you hope that the result of all of them would be the same. The computational cost is drastically different at these levels. Is it the same with the parallelism and the processes that you're describing here? Yes, exactly. So if you would zoom in also in model complexity, like adding bubble layers and cracks and whatnot, then I would expect that you would, of course, get different parameters. But right now we are zooming out. So we take the system with, for example, bubbles and so on as a system and figure out how does the system react to heat transfer and other things. And what I often also hear is that, yeah, these parameters may be grid dependent that we come up with. Because eventually the model that we use, well, the grid resolution is part of the model itself. Okay, so this is really the whole setup. And yes, this is not nice. I would also like to have something that is not eventually, not dependent on grid parameters. But if you think about what we are using in turbulence again, about the LES and Spavrensky, then you have also the filter width, which is the grid resolution part of the constant to compute the turbulent viscosity. So, I mean, maybe it's not nice, but it's how things work that you have very grid dependent parameters. So if you, for example, you're back to PMMA and you want to solve the complex physics of these bubbling layers and everything, but your cell element is a few centimeters by a few centimeters. It's impossible to capture the homogeneity in that. And what you end up with is some sort of surface release from that. And that release must account for the physics inside, but you're not solving for that. Cool. I have a follow-up for that. I know in your project you also expect to do intermediate scale with like a kilogram size samples, 50 centimeter tall ones. And the real scale, which I would assume like is like real objects or parts of the trees. If you already learn that much in the small scale and if the challenges are in making those models zoom out, you won't learn more about chemistries or kinetics from the larger models. What are you learning from them then? What we can learn from the large-scale models is how well... So, the simpler the large-scale models, the better, because then we don't have these uncertainties regarding the overall modeling. So, that's important. But what we learn is how well these parameters behave and how sensitive the outcome of your flame spread is to these parameters. Because in a cone clarimeter, you have no flame spread. So this system is so strongly driven by the heating element. So, I mean, you're putting a lot of energy on the sample. Okay, so there is no kind of dynamics given by the sample to impact the flame spread or whatever. It's strongly biased, if you want to, or strongly driven. So if we have flame spread or flame growth over a small sample, then we can investigate in computer models, for example, also the sensitivity of this parameter. And the important point for me here, and this is what one of our PGE students is doing, for example, also the sensitivity of these parameters. And the important point for me here, and this is what one of our PhD students is doing, Tasia, is to investigate the sensitivity of the parameters at the different scales and how this transfers. So imagine, let's pick one of the, no, we will not name it so that no one would say, so one of the parameters that we have that we spoke about is very important for flame spread. Okay i don't want to name something so that no one quotes me on that so yeah if there is one that is very important but it's important only for flame strip itself then maybe it is having little to no impact on the in the conch kilometer okay so it means that when we derive the parameter from the cone color meter or the other scales, this parameter, when you vary it in order to find its correct value, will always give you good results. Okay? You move it by a factor of two and the result is still good because this parameter has little impact on the outcome of your heat release rate in the coneuhn-Kuhn parameter. Okay? So this one will become very unsharp in the prediction on this scale. So you go with something that is kind of unsharp, if you know what I mean. So its value is kind of ambiguous within a specific range and moves to the flame script experiment. And the role of that parameter becomes now significant. Okay. And the question is, is this happening? And if it is, how can we find out which of the parameters at the last scale are important to do that? And how can we design or modify our approach to address this parameter? Okay. Is there a way with the existing experiments to become sensitive in our approach for this parameter? Is there a way with the existing experiments to become sensitive in our approach for this parameter? And I think that we are working on that and I think with different optimization techniques that we really watch out for all parameters and find also cost function to address them that we will be able to do that. But the question is, well, is it really so that we can kind of pinpoint or narrow down the parameters at all scales that good as it's needed for the later real-scale predictions? So two things become apparent, I think, in this scale. One is the feedback loops that start to appear and can drive the whole process. And the second is the timescale. Because in cone, timescale, okay, it is important to some extent. But it doesn't matter how quickly things burn out or how slowly in the full scale. If things happen faster, you have larger part of your material burning which means much higher heat release rate which means much stronger feedback and it's you know like self-fulfilling prophecy leading to instability specials and stuff like that the world of fire so in the full scale this feedback starts to be very interesting and now coming back to what you've learned at smaller scales, even if you did cone, at the best you've done it at maybe three heat fluxes. Perhaps you've done only 25 and 50. And the feedback will be whole range of heat fluxes from zero to whatever number you would have from a flame directly impinging on the surface. So does material properties figured out with Cone at these two levels, with what confidence they give you answers across the heat flux scales that you would find in real fires when the flame is actually spreading. Yeah, so the idea of the whole process when you come up with a process based on material parameters is that you can, if all the other models, radiation transfer and all this stuff do their job, that you, of course, can predict any heating rates. Okay, so that's the goal of it. So because it's going to work for all of them. And so what we typically do is that we develop a model based on one heat flux and then use the other one for testing. Okay. So because in the ideal case, once you, I mean, your material parameters should not be dependent on the heating rate of your heater. You know, that's not good. But you can, with this one, estimate how well or not you can get there. So that's already a good thing if this matches nicely. And what we need to keep in mind is also that we are speaking in the cone colorimeter about the heating flux provided by the heating element. But there is also the flame. So it's not that the sample will see only 50 kilowatt, but maybe it's seeing 60 plus 25 or i don't know how much but it's going to be definitely more than that because there is still the claim that is close to the surface so it provides also a lot of thermal radiation to the to the sample so you already have a wide range of radiation. But still, in the real case, as you say, you will have different properties, but I think that once these models should be able to capture. If I, as an engineer, would like to model my large-scale experiment or whatever, what exactly would I have to put in? Is it AEs in the reaction equations or is it more complicated? And the second part of the question is, can you do it with literally very simple equations that are already built in the softwares or you would have to take additional software outside of FDS? I'm thinking about, for example, the difference between Pyrolysis models in FDS and GPyro, which is a super sophisticated tool for modeling Pyrolysis that exists as a separate package. So I cannot right now go into the differences between GPyro and the methods that are... It was just an example in FDS, but yes, I know. FDS comes with all the models that you would probably need to model this. But the challenge here is really to find the model parameters. Okay. So like, let's say it's easy to predict a pyrolysis. You can know the, because the Arrhenius approach is working out nicely. And the heat conduction equation is also not so difficult to solve. That's what's the problem. But the question here is we want eventually to predict reality, and so we need to put in the right numbers for the models. So what you would need to come up with is what you all don't need to do when you do a design for the benefit of it. There is basically no interaction between the solid and the gas phase. You just predict how much mass is induced. So it means in order to have gas released you would have to do parosis which means then you would have to define what kind of reactions you would want to have. So let's say there's just one for simplicity, but all what we say is you would have to multiply it with the number of reactions. So then you would need to specify the Arrhenius parameters, so activation energy, pre-exponential factor, order of reaction. And you would have to specify what kind of gas is released. Okay. And what is the heat of combustion? What is the heat of reaction for the porous and so on? So this would be some parameters regarding the porous. The porous itself is driven by temperature. If you want to, so you need to heat up the material, which means that you need to investigate the heat transfer processes in your solid. So, it means that you have to come up with the density, the heat conductivity, the heat capacity, and all of them can provide just single values. But as I already said, you would have to come up with temperature functions of these quantities. And besides that, there is the interaction between the solid and the gas phase, especially for radiation. So you will have to also come up with emissivity. And I think the material properties like density, heat conduction, heat capacity, that's something you would need to come up, course also for every layer of a material so if you think about cables and other composites then you would have to do that for every layer that you have so i think then you would be good to go so that's a bunch of parameters and that's the challenge in all of this because as already said you don't have an experiment per parameter so that you run this experiment and the experiment itself tells you this value for this parameter so we have always this indirect measurements so we measure an integral property whatever it is each release rate for example and then deduce based on that given the model uh what are the model parameters to to get there? So that's a challenge in this. So currently, you mentioned you're playing a lot with PMMA, which is the material of choice for many fire scientists. What other materials are in your view field? So, yeah, so we've got some other ideas, which I would have to ask other people, whatever you want to share. Okay, that's okay. Sorry. But honestly, it's PMMA. Because it would be useful to really understand everything. Okay? So in this regard, its impact or non-impact on real life, it would be good from a scientific point of view to understand everything that is going on. You know what I mean? Just as a reference case, whether it's going to have any practical applications in engineering or not, I understand that, but it's not going to get easier than PMMA, to be honest. So with the PMMA, some time ago on the conference, I saw your results on modeling vertical setups with walls of PMMA facing each other. And you were running that experimentally. You were running numerical simulations. It seemed you had quite a good degree of success with those. So how now you feel about the capability to model this in large scale? I also think this is a part of your McAfee experience, right? Exactly. So, first of all, just to make sure, and I'm sorry if I gave you the wrong impression, so we did not run the experiments. Oh, sorry. That was generally my bad. Okay. No, no, that's fine. But I think these are the colleagues from, I don't think I know, but the colleagues from, I don't think I know, but the colleagues from NIST run the experiments, so they did a great job for that. So if the impressions were there that I was running them, that's definitely not true. These experiments are part of the FDS validation guide and of the MacFP part for the solid phase. And yes, we work on the prediction of the heat release rate and relative heat fluxes on the walls and so on. And if I may advertise it here, we just published a paper on the full process. I was just saying from the micro scale. I think it's named from the micro to the real scale. Fantastic. I'll link that in the show notes. Great. So it describes the whole process and what we learned also in the interaction with all the other colleagues at McAfee and there will be at the IFSS a workshop on that. So maybe you can advertise that as well on the McAfee that the real scale experiments come up by themselves with challenges, as already said. So what we want to do in MacFP, like this was, I think we extended our view on that, is to see like how well do the material parameters behave. Okay, so this is what we all said. Okay, everybody comes up with material parameters and then we test them on different scales and also go to the real scale. The problem at the real scale is that there are more effects that we would have to cover. Okay, so there seems to be a flickering of the flames that you would have to include into your model as well. They may be in homogeneities in the burner itself, so that they sent, I think it was sent burner. Anyway, this doesn't seem to be so homogeneous as you assume it in your models. So you're starting with a model that may already come with deviations by itself. And then it's hard to judge how well do your material parameters now perform. You know what I mean? So there are some other uncertainties in the setup and also the interaction with the gas phase. So what kind of fuel do you release from your sample? And what is the relative fraction of that? Which has a huge impact. So it's because it's not as in the gas burner, it's not methane or whatever that you know um but it's something something different yeah so i think the next steps are definitely to combine also the gas phase mega fp efforts because fire as you know is a combination of all these things and i think we all know that we shouldn't be so naive that we can separate things. We need in fire what distinguishes us from combustion community and so on, that we need to take care about everything. And I think this is the point where we need to work together also with people investigating the gas space and the real scale. Because this is now you know then you get more uncertainties then for example the gasification apparatus where there is no combustion that's that's fine but well zooming out means you have to take more processes into account and to finish this is a very interesting interesting discussion. What happens when you have complexities to the materials? Because we're not building buildings out of MMA. And I would expect even at the simple in homogeneous materials like textile covered foam materials like the ones that insulate my children from the podcast audience or upholstered chairs up to very complicated materials where you have multiple different plastics all together. You've mentioned recession cables before. That's also a complex material. What are our chances against those complex materials? I think there are two approaches. One is, again, to stick to effective models, which are probably fine. So you say, this is a complex material, so many layers, many different layers. But I want to have a model that presents its interaction with being heated up with fire eventually. So the outcome, to predict how does it release mass and what kind of gases are released, combustible, non-combustible, and treat it as one surrogate model for the material. Okay? So I think this is not how we do it right now with many things, but I think that you can also work with that, probably with composites. But this may not be true. Okay? probably with composites. But this may not be true. Okay? Because you may have things that really significantly change their structure in the process of heating up, and there may be also time-dependent things going on. And then, maybe these things don't work out. The other approach that we are trying to move into is to look really into the materials. But then things will become less applicable for kind of everyday engineering applications, but be more for the kind of research part, at least at the moment, at least, where you would really model what is going on in the solid phase. And of course, then we have to come up with different models. So then FPS will not be sufficient. But the idea is to team up with people who really do material science so that they can really go to really low scales. I mean, for homogeneous materials, maybe you can still stick to that. But if you think about timber or paper or other things that have small structures to really work on that scale and then move up up to bigger scale, so that you have also then effective models, but those that are based on kind of different scale investigations. And to, for the end, to twist the discussion a little bit, how do you feel about efforts going the other way around, you know? Like forgetting about the small scale, the chemical properties, and just having large full scale experiments, literally measuring the flame spread rates with cameras or other visual tools and fitting models with machine learning or something based on that. great efforts on on this calorimetry database that was yeah that went through an ai and ai now can uh predict to some extent how how big fires are and how things can burn so so how do you feel i mean for me the immediate problem is that it doesn't take into account the context of the of the building which means again we're in the design fire versus flame spread discussion so um first of all again i think the diplomatic answer is this is just another tool in the toolbox of an engineer okay which is i don't want diplomatic give me what you think don't worry um the so science is is nice you must have different approaches so and you need to diversify all the approaches that's good to have. So for me it's hard to judge how well these models rework when they kind of see, especially the AI models, situations that they haven't seen before. So what new things can we learn from that that were not already part of the training? So I cannot judge on that. Me as a theoretical physicist and now as an AI, becoming part of physics, we start good laws like equations to describe these things. And in other disciplines, when you go to material science, this is what other people do. They can really do the interaction of small, now we're talking about really small structures inside of the material. And we should, or we can also learn from these communities a lot. And so this would be also an approach. And like, if the model, the AI model, never saw water mist, will it now predict how the couch, if you stick to that, will the heat release rate of the couch will change if at one point the water mist system is turned on or off. So now I think that's another toolbox. Right now we stick to the classical approach. However, in the BISCID project, one of the goals is to actually come up with an AI model. Okay. But to predict the material parameters. Okay. And it's a different approach. You know, the prediction itself is still done by, in our case, FDS. But the way of finding material parameters, so, for example, we have an in-house code that's also freely available, which is called PropT to do the inverse modeling. Now, we use a genetic algorithm for that, but the idea is to do the optimization process with an AI model. So basically, the AI model doesn't predict anything. Well, it predicts the material parameters, but then you check it. And if they fit your experimental data, then it's the same as the classical optimization would do. But of course, we hope that it's going to be way faster. Because if we go back to Basquiat, the engineering companies that work with us, the main challenge is to find the material parameters. The actual simulation, that's fine, but we need to find the material parameters. The actual simulation, that's fine, but we need to find the material parameters. This is super costly. And they want to have a quick way to come up with the material parameters. And that's where our AI model kicks in, hopefully, to provide a good estimate, maybe as a preprocessor for a kind of classical optimizer to come up quicker with deep material parameters that they can use for their application. So there are different ways to use AI of course nowadays but we in that case we wouldn't use it for prediction but only as an optimizer. Fantastic. Lukas, thank you very much. Probably more difficult than usual episode for everyone. But I think for people who are working in this field, they found a lot of inspiration and answers in that. And for all engineers that see challenging simulations with flame spread, fire spread, it's not as easy as it looks. And I um, discussion gives them another depth into what does it take to, to, to model things and, and how much effort it is. And I'm really happy with the Mac FP. I mean, I'm really looking forward to Japan and it's going, it's going to be incredible. Hope to bring up those, this research and, and, uh, those experiments to the audience of Fire, Shine, Show as well soon. So thanks, man, for being here. And all the best. See you in Japan, man. Thank you very much. Yeah, see you. And for all the others from the listeners, reach out to me. And I'm very happy to discuss things with you regarding flame spread. And maybe we'll meet in Japan. Thank you very much for having me. And that's it. Thank you for listening. in Japan. Thank you very much for having me. And that's it. Thank you for listening. As you heard in the episode, it takes a lot more than some people think to model complex materials and complex fire interactions. Just a list of properties that you would have to account for and phenomena that you need to account for when modeling simple frame spread on quite homogeneous material that Lucas gave is simply astounding. It's not so easy, but definitely worth it and definitely needed for the evolution and future in fire safety engineering. Bear that in mind when someone approaches you claiming that they've just modeled flame spread over complex material in a compartment fire and they've done it at 20 centimeter mesh resolution and in one day that's that's not really the thing that that we are looking for so hopefully the world of fire modeling is a little bit closer to you now and yeah let's cross our fingers for the developments in basket project and developments of lucas team and let's see where the world of modeling goes. And the next chance to update on what's happening around this, and I've assessed Congress in Japan where there will be MacFP workshops. I've covered MacFP with Arnaud Trouvet in the podcast previously, so my hopes for this workshop are very high, and I hope we will see a lot of interesting data that will help scientists develop their models in the future. That's it for today. Thank you.