 Hello everybody, my name is Wojciech Węgrzyński. I'm a professor of fire science at ITB in Poland and I'm super happy to welcome you to another fire science show episode. We had a great streak of amazing episodes lately and I hope today does not break that streak because I am interviewing two absolute stars of fire science. That is Professor Steve Gwynne from Movement Strategies at Lund University and Dr. Mike Spearpoint, the research lead at OFR. And I'm going to talk with them about industry-led research. I'm going to tell you a little more about the episode in a few moments, but I really cannot wait to give you the big announcement of this year, the one that I was teasing in the previous episode. teasing in the previous episode. So it finally happened. For the year 2023, the Fire Science Show has partnered with OFR Consultants, who are now the diamond sponsor of the podcast. This is good news not only for me, but for everyone, because it will allow me to produce this podcast without any paywalls or limitations in the high quality that you expect and with all creative freedom that I used to have. So I guess it's a win-win for everyone. I am also very happy that the partner of the podcast is actually Ofar, who is a company that has a great set of core values that are very close to my set of core values. Ofar was built by fire safety and risk engineers for the purpose of doing fire safety and risk engineering so they're very focused and aligned with what we are talking about in the podcast it's also a company that does a lot of research but that that's you're going to learn from the today's episode with OFR we have a lot of things in common and I am super happy to work with them to provide you this podcast as it was, or maybe even better, for at least one long year. So the show is not going anywhere. I don't want to ramble too much about the collaboration details, and I will have a Q&A episode planned for later this week, where I will be answering the questions incoming and commenting the listener experience survey that went out in December. I've gathered a lot of feedback and I would love to comment on that. And also it will give me a chance to talk about the OFAR partnership and how it will unravel for the podcast. What does it mean for the podcast? What does it mean for the listeners? If you would like to know that, join me in the Q&A episode. Now back to the podcast episode. Mike Fairpoint and Steve Gwynn are sure legends of fire safety, and they both come from very interesting backgrounds. Both of them have been academics. Both of them worked for governments or in some sort of governmental laboratories and supported their careers. And now both of them are research leaders in large engineering companies, and that's why I've invited them. Because when you look at the fire science landscape, it's obvious that companies do a lot of research, a lot of useful research, a lot of impactful research. And I would like to understand why. Like, why are they investing in science research? What are their KPIs? What they want to get back from that? And how it actually works, how it differs from academia. I think it's a very interesting thing to discuss, especially that the podcast is listened by a lot of young people who struggle with their life decisions, whether to go academia, whether to go industry. I can tell you both roads are great, and I hope this podcast episode will show you that the differences in some aspects are maybe less than you would think of. So that was a very long intro. So let's not prolong this anymore. Let's spin the music and let's go with the episode. Welcome to the Firesize Show. My name is Wojciech Wigrzyński and I will be your host. OFR Consultants, a multi-award winning independent consultancy dedicated to addressing fire safety challenges. OFR is the UK's leading fire risk consultancy. Its globally established team has developed a reputation for preeminent fire engineering expertise with colleagues working across the world to help protect people, property and planet. In the UK, that includes the redevelopment of the Printworks building in Canada Water, one of the tallest residential buildings in Birmingham, as well as historic structures like the National Gallery, National History Museum, and the National Portrait Gallery in London. Internationally, its work ranges from the Antarctic to the Atacama Desert in Chile and a number of projects across Africa. In 2023, OFR will grow its team, and it's keen to hear from industry professionals who want to collaborate on fire safety futures this year. Get in touch at ofrconsultants.com. And now, back to the episode with Mike and Steve. Hello, everybody. Welcome to the Fire Science Show. I'm here today with two great experts. First, Professor Steve Gwynne from Movement Strategies and Lund University. Hi, Steve. Hi, Hezik. I'm doing great. Thank you, Steve. And Mike Spearpoint, Head of Research at OFR. Hey, Steve. Hi, Isaac. I'm doing great. Thank you, Steve. And Mike Spearpoint, head of research at OFR. Hey, Mike. Hi there. Nice to see you again. Yep. Happy to have you on one of the most requested comebacks to the podcast by the audience. That's a heavy burden, Mike. I hope we can all carry that. Guys, that's an interesting topic proposed for today's session, which is industry-led research. And the point of this discussion is, I guess, to understand the role industry has in building up fire research, maybe even fire science. From the email exchange before the episode and the little discussion we just had, I guess it's nice to start with the fact that we have research, science, and development, which are three things, but maybe three different things. So maybe one of you would like to start on where's the research in the grand scheme of science? So I'll speak from the evacuation side of the equation, right, the human behavior side of it or the people movement side of it. of the equation, right, the human behavior side of it or the people movement side of it. I think because it's, in comparison to our understanding and practice of fire science, it's a less mature field. Oftentimes, the practice of it in industry requires more dedicated research because there's less boilerplate out there in order just to do the thing in practice. So you end up doing quite a lot of background work, even in those projects that are not dedicated research projects, but are a consultancy project, but actually it involves new thinking. So in my head, research in that context has value beyond the specific consultancy project on which you're working. And that may actually be a new method or actually going out and collecting new data. It may be applying it in another way. There's value beyond the lifetime of that project that might help others understand the problem or help someone within the company do the thing again, or indeed, more broadly, provide insights into how that should be done or might be done by others in practice. So much like all research, it's meant to advance the field, that that field may be on multiple front pastures, I guess. But does it mean that we're missing so many puzzles that it's a necessity to do the work you're doing? Well, I think it's a slight misrepresentation, I think, to ever think that the field of knowledge is complete or stable. And think of what happened in the pandemic. We thought we understood a lot of things and we certainly didn't. And we had to scramble to update that understanding. I think that's very much true in an area such as human behavior and fire, which is very sensitive to changes in design, to changes in technology, to changes in demographics. So you've got multiple different influences, very few of which are under your control, but you are subject to their impact. And then you have to understand the response. And this is both true of research and practice. There's a constant need to update your understanding. And that inevitably requires someone to go out and do the dating. And that could be a dedicated researcher or someone engaged in a research task. If I'm not suggesting for one second, it doesn't also exist on the other side of the equation. But I think there's a bigger pile of practical processes that have been applied over a longer period. I think Steve brings up some interesting points there and now I'm going to dive into my amateur philosophy here. Well, you know, the idea of knowledge and what we know, I might drift off to what we might call the Donald Rumsfeld model. But we've got this sort of thing that Steve brings up here where it's kind of like there's an understanding of what we might call the fundamental mechanism of the universe, chemistry, physics, or whatever. We know we don't know everything about it. Maybe there's a possibility that one day we might know everything about it. But from my understanding, they're kind of fixed, right? Whereas there's the sort of things that Steve's talking about, which you might call the research around society. But society is changing, right? So, you know, the way we live now is different to previous generations. So the way that people organize themselves, the way that we have our sort of acceptable levels of risk and all sorts of things. So there's a kind of ongoing research there that's just sort of societal work. going research there that's the sort of societal work and i'm thinking about for example bringing up some research well myself and steve and you've had ann templeton on before well and as part of that work has been looking at things like how much people trust current guidance in terms of fire safety well that's a societal question because that's a moving target as people are exposed to new events and their behavior change and family structures change and their demographics change those things are never kind of fixed in the same way that we might understand chemical reactions so there's quite different types of research in terms of those those sort of that spectrum when steve brought this this topic my immediate thought was that that's interesting to talk industry-led research because in fire science, I think when I look over the last years, the best papers I've read, a lot of them were industry-led. It was literally coming from companies. So many interesting projects, developments that were carried by literally commercial companies. And I don't necessarily see a very direct link between research and revenue for a commercial company. I would expect it's like when a company does something, they would do it for revenue because it increases their commercial viability. But I see that's not the case in fire science. And it really intrigues me because, you know, I'm coming from a cultural circle where the scientist is the one at the top of the mountain and they give you the knowledge and you are very welcome to apply that. welcome to apply that but having the idea that a company a privately owned company that is in essence maybe driven by profit would do scientific fundamental research it's not something very obvious to me and yet in fire science as i venture outside of my cultural circle i see that a lot and it's more that that's really working do you think we all irrespective of where you are you are working with a specific currency, right? And in academia, that currency could be publications. I'm simplifying, but yeah. And in industry, currency maybe involves several different examples. So it could be publishing maybe another currency. I'm certainly encouraged to publish. Eight is to make sure we share the insights provided to demonstrate competency and subject matter expertise, and also to try and shape the area in which we work, right? I mean, part of what we do actually in practice is in some ways to influence the next generation of work, be that through the research that we do or through the practice that we do. You mentioned about why would an industry want to do it. I think what has evolved over the last 20, 30 years is that the idea that research is only done in one place, I think, has evolved somewhat. And I think there is a natural home for it in academia because of the currency, because of the currency of publications and student development and so on. Industry has access to different types of resources maybe that academia doesn't. It has an access to ongoing real world problems that it has to address. So one of the classics at the moment, I guess, is the access to large pots of what they call the data reservoirs that companies collect, that industry might interact with on a more regular basis that the research in an AMIC environment might not have access to. I'm not saying it shouldn't have access to it. I'm saying it's just less direct. And so that's why oftentimes an industrial partner is so welcome into a research project because it provides that bridge to the ongoing application of expertise and practice. I also think, and then I'll pass over, I do think that, and I say it's very unusual to have three people in a discussion that have or are working in government, industry and academia, you know, or at some point in their career. Yeah, yeah. I think in my head, I see them moving at different speeds. Typically, and I'm simplifying, industry deals with the shorter term or can deal with the shorter term. Then you have academia, which you're trying to say, what do we know about that thing? And then government, which is how do we use that in the longer time frame. Historically, academia was the one that was responsible for shaping the new knowledge. I just think those lines are much more blurred now. Absolutely, they blurred a lot. And when I see direct gain in this short-term research that you've mentioned, like direct answers for questions maybe, but I also see a lot of fundamental research that may not lead to a direct breakthrough, direct discovery, not something you can build commerce on for sure. So there's also some sort of this higher motivation, which I would expect from academia, not from a company. Yeah, I just wanted to sort of take that thing that Steve talked about, the blurring of the lines and how long that's been going. It might be hard to judge. Again, when we were kind of preparing for this discussion, but we kind of sort of touched on this. But in the end, when you look at, there's not this simple delineation between industry research and academic research because there's people in industry who interact with academia they co-supervise students and partner with universities they might be i mean i know steve's a professor at london university so there's interaction that way and of course there's interaction the other way but people in academia may be contracted to provide advice to industry, so there's that synergy there. Some academics will end up developing a product that might be span off by a university and still be a stakeholder in that product development. So there's this kind of, you know, some people think there's an idea there's just sort of academic research and industry research, but there's a much more melting pot of people who are interacting across those you can call it a boundary but it isn't really a boundary it's a it's a continuum of those two i suppose at two extremes you might think of one end industry research being very utilitarian it's solving a problem for today that needs to be solved and the other end of the spectrum is kind of the academic side, is research is not there for any utility. It doesn't matter whether it's useful or not. It's part of civilisation and humankind is to do these sort of thinking, and it doesn't matter what the value is. But again, I think there's, again, quite a wide continuum to solving tomorrow, today's problem, to not solving a problem ever at all. Somewhere in between. There's a lot of in between there. I do think, sorry, I think it's an important point is if you think of fire safety or fire science or fire engineering, all of these things are, unless you're working at the extreme limits of fire science, one end, it's a pretty applied area. Like the journey between us and engineering is much shorter than it might be in some of the more pure mathematics or particle physics. Yeah, yeah, whatever, you know. And so that distinction, as Mike said, is much grayer than it might otherwise be. I also think as well, don't forget the many universities Tivoli consult. So there are many research departments that supplement their income through doing either model development or supporting a consultancy or doing spin-outs. So it's not just a land grab of industry trying to hoover up or grab research. I can't think of a project where I've been involved in where there was universities, industry and government presence that would have benefited by only being one of those. I would consider myself in this role as well as a research institute that does actively consult, being underneath the government's wing, having a certified fire laboratory, having a consultancy practice, and being a scientist at the same time where I have to publish papers, do fundamental research. I often also take this chance to do selfish research. I think I've said it many times on the podcast that I try to research things that are very relevant to my practical work. And I highly appreciate, actually, the capability to have real-world problems at hand. I see that, especially when reviewing papers, many researchers over-deliver on the promise, like this paper will serve either fire investigators in this way or this will change the way how we detect fires in buildings. Boy, no, it will not. I mean, it's an interesting concept, but it's concepts we have a lot, solutions is that we lack. You think this, having this exposure to real world problems is something that anchors this science to the realm of usability? I think, well, first of all, humility is a great thing. I think overreaching is one of the more dangerous traits a researcher or a practitioner can have. I think the goal is often subtly different as someone whose role has been to try and develop a research capability and bring in researchers. The natural instinct of a researcher is to keep pushing, to keep going in a certain direction until they've gone as far as they can. And within the lifetime of a project, they may not have that scope. And that is a limiting factor in industry, whereas you have a clearer deliverable that has to be met. Now, that doesn't mean you compromise the message. It means you target that particular problem, but then you may continue beyond it and publish the broader work or publish, you know, and produce something that's genuinely novel in the field. But there's a twin track of doing what needs to be done for the thing in front of you so that it's good enough. And then answering the broader research question, which may require future or more broader thinking or future work. And then actually into a policy or regulatory structure, which is almost bringing it, reining it back in and saying, well, OK, this is what we know is going to happen. Well, what can we really expect to influence on a broader scale? So there's that sort of tug of war going on, I think, in terms of expectations. But what you can't do is compromise the message. You can't change your subject matter slash expert opinion to suit a particular client. You just make sure that the message is understood in the context of the project, and it's suitable for the scenarios you're looking for. I guess that's a slightly different question. Yeah. Mike, is it any hard to keep this integrity? I don't think so. No, I don't. I don't think so. It's important, but it's important to keep it, and if you want to keep it, you will keep it. I think it's a personal thing. It's as much about hiring the right people and having oversight. And also, I think as well, like it goes back to that currency thing, right? The currency of publications and the currency of quality of work. Work is really scrutinized in an industrial environment. It's not just pushed out the door the reputation of an engineering company that has a science background and that is producing intelligence in one form or another if you if you're caught sort of um cooking the books or taking shortcuts that is a quick track to undermining your reputation and as as corporates would call it their branding I mean their brand, you don't want to be caught doing that because those shortcuts cost you a lot of money and potentially existent. If you can't be trusted and you don't have processes in place, just as academic institutions have put those processes of oversight and ethics equivalent, we may call them different things, but we certainly have oversight and we certainly even refer to those type of ethics requirements as and when they're appropriate from other external organizations. I mean, as I was saying before we start the conversation, I mean, I happened to be doing a little talk on ethics last week at a university. But of course, all of us are engineers and when you're a chartered engineer, you're all signing up to an ethical framework. So in my case, the Engineering Council and then through the Institute of Fire Engineers. So those ethics are, like Steve says, they're similar or if not the same for academia. might say from your personal, I mean obviously you've got your employer, your industry, the ethical standards to meet there. But then of course you've got your own ethical standard. And part of that discussion I was having last week was some of these things, some of these questions can get quite tricky in terms of what might be seen as right and wrong. And again, I dare not delve too much into my amateur philosophy. I've got a whole lot of morality to read that I've just bought. So I'll come back to that. And another one called Ethics in Construction, which I need to read. So that's another day's reading. I do think, Mike, there is a more basic level. Whatever we do, whether it's in research supporting a project or even a dedicated research project in and of itself, the outcome that's going to be produced is undoubtedly imperfect, partial, and potentially incorrect at some point as assessed in the future. Most, if not all, scientific understanding will be overthrown in some form or another. understanding will be overthrown in some form or another and especially in engineering and in in engineering research or practice it will be supplanted by some better approach and some plan for by more appropriate data so that humility that you need going in and the associated skepticism that you must have to question the validity of what you're doing and that validity can get into ethics and it can get into process and it can get into presentation and sharing as much of the background information as you can and that sort of transparency. And you mentioned it earlier, Wojciech, about reviewing articles. You know, if you've got the sufficiently seasoned eye, you know where people are not being sufficiently transparent. You know where people are not unmasking something because they're somewhat tentative about sharing a detail but i think it's just better to acknowledge right up front like this is everything could have been done better if you'd have started it at the end of the project yes when conceptualizing this talk i had this immediate example of where the industry-led research could go rogue. And there is a case when someone would be researching a feature of their product, and by this research they discover it doesn't work as expected. And I guess this would be a place for the most difficult choices to be done. Like, do we stuff this into a closet and never surface this research? But these things also have a history of backfiring, like what you said, Steve, about the reputation gains. And for a long time, I thought this is an industry, this is a very specific industry problem. But then I came to the realization that, and now I'm going, I'm at your philosophy, Mike. Many researchers would invest their lifetimes in their theories, and they would be very dependent of the theory, even when faced with the proof that it's different. Like you, Steve, said, inevitably, it will be superseded by something better, either a different concept, either a more precise definition, either by realization that there are more variables in the equation that completely change the outcome. It will be superseded. And this process is very difficult. And here again, you may be a scientist in an ivory tower and find something that contradicts a lifetime of your discovery, and you would be confronted with the exact same problem as an industrial. For some reason, I felt that industrial, it's like more obvious or more easy. But now I see the academic would have the same problem, right? Unless you're, where is this view of, there was this i don't know like in the victorian era in the uk there were these like gentlemen scientists self-funded who were working out of their shed in their garden and they just came up with these stunning findings unless you're a modern equivalent to that or an absolute genius you probably work in a department you probably have to get funding and you probably do align the broad path of your research with that so the idea that you have carte blanche over what you look at and how you look at it in academia is somewhat partial i think it's unusual do you actually do that yeah i mean very few people i think have complete independence in addition i think there's a broader, and we go back to the currency of publication, is how much of public... Do people publish all their results? Yeah. So you publish your failures. Do you publish where P isn't significant or whatever it is? Do you publish... And that may be unbelievably important that something doesn't work or that it isn't important or that a classic in fire, that it was a near miss, that it wasn't an actual fire that caused loss of life or huge damage. And so it might not appear on the radar as much, but there might be enormous lessons that we might learn from that potentially less significant or less dramatic or less complex incident. So the idea that there's this area where there's a purity and then there's this horrendously corrupt evil twin, I think is, again, a little bit complicated, a little bit simplifying the distinction. Again, I think a lot of it comes down to transparency. And by the way, there's plenty of research across all of the various domains that isn't quickly published because of various restrictions. And that can be in academia or industry. I mean, obviously, the goal is to publish as much as you can, especially where you can generalize from the specific project. I think that's the biggest value. But then assuming that imperfection and assuming that it will be supplanted by something else, I think that's just good humility. And transparency is part of that process, I think, because it allows you to be further scrutinized. Talking about the currency, what is the value of publication for you? For me, it's very simple as an academic impact factor. We have points in Poland that are, there's a list of 50,000 journals, and each has assigned a point value. So we joked that we gathered the points and we turned them into hot dogs in a petrol station from a cart. What's the, like Mike, if you publish a SOFA, what are you looking for? Are you looking for impact factors? Are you looking for another metric? Are you looking for accessibility, reputation, prestige? Yeah, it's a good question. And again, there's been a bit, I happened to be on the editorial board of Journal of Fire Sciences, and there has been a few emails between the editors, which I half-drafted and never sent it back. But this discussion has gone on there. And certainly, I i'm saying within academic administration i don't necessarily mean the university as long as it's governments now they want to come up with a ranking system so you can compare one department or one university with another and they and somewhere we've decided or it has been decided the impact factors is somehow some kind of measure of quality and whatever. And, you know, I think a lot of us recognize both in industry and in academia that this has fairly limited applicability, but it's nice to get a scoring system because, you know, you can rank A above B and so on. And certainly then for industry, I mean, and I'm sure Steve would have a similar feeling, but impact, because we don't have in industry, have that scoring system, then impact factor on a journal doesn't matter. I'm not sure it's ever mattered to me, the impact factor of a journal. I mean, for me, the choice of journal is partly, there's a whole bunch of factors that you might weigh, and it might be the audience you expect it to go to. It will be the perceived quality of that journal. And it might be the speed of publication. It might be the fact that they might have open access. So in some cases, you know, if you're working for an industry and they want that information fairly quickly published, then an open access journal might be or an open access pathway in that journal might see it as more valuable than some of these other factors. I mean, again, from industry, concept of impact factor for some people probably is not something they've ever heard of, and it bothers them. So the choice of journal has all of these sorts of elements that go into it. Maybe I can come up with a scoring system that why choose a certain journal, dare I be perverse, to come up with a scoring system of why to choose a certain journal in a certain situation of weightings on all these factors and give each journal or each paper a score on why I chose it. So that would be, put it in an impact factor journal just to close the loop. So the choice is not, I don't think it's a simple one. And if someone said to me, why did I choose that paper to go in that journal? I mean, some days it is simple as that, as I've three papers to journal A, maybe it's time I sent it to journal B. I mean, it might be just sharing it around type of thing, which maybe some might look at and say that's a really poor decision making, right? But if you had to make a choice, like you're the research leader in your company so I guess you have some say in where the people go, or at least you advise them. If you had in one hand, let's say, Fire Technology or FISA Journal. On another hand, let's say some IEEE informatics conference, which may in the end have higher impact factor, but will not reach your FIRE audience. It matters for you that you publish in a place where your industry reads, not necessarily just the metrics that represents the vehicle where you publish it, right? I think that's changed a lot with social media. First of all, I mean, I think Mike and I are both in pretty privileged positions in that we're both encouraged to publish by the companies. And that's because they didn't hire researchers as lip service. They actually wanted an ongoing research capability, and part of this is demonstrating that, right? So there's value to the company in publishing because it shows they're actively engaged in this type of thing, and this type of thinking, and they have in-house capabilities. In terms of where this is the problem with those impact factors, right, is I wonder how accurate they are now in a lot of ways, because how do they capture the actual reading of the documents and the actual influence? I've never paid, to be honest, a blind bit of notice to impact factors. I'm more interested in the authors that I'm publishing with. I mean, I'm pretty much a social butterfly when it comes to that. I want to collaborate. So I like to be working. I don't care where I'm in the author list. As long as I'm contributing something and there's five or six people on the paper that I've got to learn something from, and that's great. And the company benefits because they contributed to the work and their staff are seen to be contributing to it and they've advanced the field. And if you're in our game, there's great value in showing that you're, you know, it's another way of gently nudging both the understanding of the field and the way that the thing is done, right? So you're advancing innovation in that way. I think there's personal preferences, as I said, I look at the coalface more than the person publishing it, but the organisation, I think, benefits from enhancing that reputation of new thinking and knowledge generation. Also, they have those connections as well. So rather than the people, the authors, the institutions to which those authors belong, I think there's increasing value in building those bridges between different organisations and showing that you can get active on those research projects. I think the notion that there's journals that the industry reads, and again, I think Steve's meant that with social media and also the internet. I was kind of looking at this just for this other discussion. I don't have a kind of reading list of journals like I might have done in the old days that were printed and sent to me or whatever. It would be really interesting to sit down and look at all of the journals that I've cited and where they come from. And some of them will come from what you might call the mainstream fire science, so fire safety journal, fire technology and those, fire materials. Some will come from the built environment, so, you know, a wide of that. But I've got, you know, given I've dabbled in too many subjects, and maybe I'm, you know, guilty as the next person about not sticking to my knitting. I mean, I've got, you know, I've looked at papers in stuff on occupant loads, ending up looking at papers on retail research, consumer research, and the stuff I did on kitchen oil fires. I looked at papers to do with how many people dispose of their kitchen oil down their sink type of thing. So these are all way outside of fire science stuff because they just happen to be what I was looking at. So this notion that there's some journals that people read and others they don't, I think has disappeared because the Internet and Google Scholar and that sort of thing means you just search and you find where you find it and you make a judgment. And again, there's this idea about quality of the journal and that. And I don't know, I think a reasonable researcher can look at a paper and make a decision about the quality of the paper and so on and so. of. It was, let's say, independent of where it was published. I'm being a bit careful about that because maybe that's not. I think, Mike, I think the reason I've mentioned this is because it's come up recently in some work I've been doing, is if all you did was search academic journals, if you were doing some search for information, you'd miss out, especially in our field. All of the work that NIST did, a lot of the reports that NRC did, all of the government publications wouldn't necessarily appear in that. There's lots of industry reports that wouldn't appear. There's lots of, I mean, some of the blogs that are on LinkedIn now, some of the pieces are actually well-referenced and well-documented. And it's a way of getting content out there now quite quickly. The problem with the journal publication process is it can take a long time, like a really long time. Mike also mentioned that the speed of publication would be one of the factors. I'm asking about this way, like if I receive a research grant as an academic, I have to point out some milestones and some outcomes of this. And these outcomes are usually the easiest way to define it is I either train a PhD student, I've promoted someone and there's a growth of their career that's measurable by them obtaining PhD, or I publish something which has a certain value. These are simple, easy metrics that are very measurable, very identifiable, very obvious. You have a publication, it's a publication. There's no gray zone in that. Did you make an impact on industry? That's a gray zone. So I wonder, doing industrial-led research, what indicators would be there that you've actually achieved that if paper on its own is not the achievement of it? Yeah, it's an interesting one. As I said before, not all, any research that's done can be published. There's always bits that are more sensitive or for various reasons can't be published. done can be published. There's always bits that are more sensitive or for various reasons can't be published, but assuming you can publish it. To me, the ultimate impact of industrial work, again, industrial research, beyond the lifetime of a project is to get into the regulatory or guidance space, right? Because that means that you've generated something that is sufficient to have an impact on the broader practice beyond your organization. So just as, and it's absolutely pragmatic, right? It's absolutely applied, but it's one line in the building code can have a much bigger impact than 10 articles that no one reads, where someone's got to use that one line or providing a material base for the development of regulations. To me, that's always, if you think of it as like you've got subject matter experts who are engaged in this and or research, and what they're all trying to do in one way or another is either do something to such a high level that they're noticed for doing it in a new way that's advanced the field of practice,'re noticed for doing it in a new way that's advanced the field of practice or they're doing it in research where they've expanded the understanding and or the area of knowledge that then bleeds into the field of practice eventually someone is going to develop a guide to say well this is how you do that this is how it should be done based on that new practice or new research and and then eventually, of course, beyond that, it's, okay, this is how it must be done. So to me, that's the signal that your novel work inside of your practice is having a broader influence beyond the day-to-day or beyond the life of the project. And it's where you're shaping the space. Took the phrase out of my mouth, like shaping the environment. Like you really did change the landscape in which you business. Mike, for your company, you're seeking the same? I mean, you're in a very interesting position because I know OFR is carrying a lot of government, like where the government is directly your consumer. And they give you, they tell you what research to do. Yeah. So we've got some government funded research and one of those projects i'm doing jointly with steve it's one of the ones i mentioned and so they've got certain goals for doing that research and i suppose when i worked my first job um when i worked at fire research station bre i mean obviously there some of that money came from government departments. I mean, I can think of one where we were asked to look at a piece of – there were two different standards for smoke detectors, for commercial ones and for domestic, and part of the work was, should there be one standard for this? So it would have had an impact on the testing of those devices, which was sponsored, as I i remember by the government department because obviously that had a societal impact on whether that standard be changed or not well i mean from a so i get on a personal point of view i remember having a discussion not that long ago with one of my colleagues about how much my research i I've been involved with has had an impact and I kind of struggled I don't know if it's had any impact at all but what is that impact some someone might say well if you could demonstrate that all your researchers as we might say sort of saved a life then you kind of think it's all worth it it's really hard um so it's really difficult because i because i was saying to this colleague i'm saying well maybe sometimes i think well none none of it's made any difference but then then this colleague sort of said well it may be a difference it may have influenced people to get into fly research or or influenced involved with something like otherwise yeah it goes i guess that's an impact in a way that someone's read something of mine and he thought it was useful or it was a completely wrong way to do it and the better way was to do it another way. Some researchers might point to a better method. And so that influence has kind of said to me, don't do it Mike's way, because that's a rubbish way. Well, that's what I was going to say is I've had the other experience where I've just had someone randomly come up to me at a conference and start arguing with me, like, on meeting me because of a paper that Mike and I worked on many years ago on model defaults. And they were fairly furious at what we'd spoken. And so it definitely influenced their next paper because I think they were quite critical of what we'd written. But so, no, the thing is, you don't know. You don't know what the impact is, right? And I'm not that prolific, but it's like, you see, I've seen quotes from the most obscure paper that I ever wrote or whatever, and they're holding it as like a bit of evidence that they're used to contribute for their work. And it's like, it was a Korean, and they spoke to me at a conference. That was really useful for me because it meant, not that it was anything profound, but it just meant that was a little stepping stone that led them to something else. And I'd included stuff in my reference list. You never know where it becomes useful. I would say, going back to usefulness, and I think the reason for doing stuff as well. Oftentimes, again, I do think the assumption is slightly naive that, you know, if you're in one space, like an academic space, you have control over what you're doing. You have much more purity in selecting what you look at. And we all need funding. And that funding comes from a body. And that body has decided that something is important and needs to be looked at. And that is usually determined by a combination of stakeholders, government, industry, advocacy groups, whatever it is. And we were very much subject to that when I was working in government. To me, a classic example, maybe it's unique, but it makes the point, is what happened during the pandemic, right? Everyone suddenly had to turn left and do things in that, or not everyone, but many of us would have said, okay, you're going to stop looking at that thing and you're going to turn left and work out why social distancing matters or what impact that might have. And so basically all of the machinery that was normally focused on these, this unbelievably complicated and addressing all these different topics. It's like, everyone's going to look in that direction because it's basically shut society down. And so the reason I mention it is because an example of the fact that often we're quite reactive to needs in that either industry has to address on a project-by-project basis or research addresses given the funding that's available. It's quite rare, I think, that someone genuinely stands up and says, I've got this idea that's so important. I want a dedicated bit of funding for it. It's typically much more influenced by what's going on, or not necessarily at that moment, but over a period of time. If someone from inside your company came to you and said, Steve, I have this idea. It's not something we can immediately employ, but I think it could be eventually important. I don't know. I need to research that. They next thing do that. Would you go for that? Well, that's literally an ongoing process, right? So to me, there's different types of research projects. There's like a research offer. We do research for external entities and we deliver research outcome. So that's one type of project. And then there are relatively complex people movement projects where it requires us to do research in order to facilitate those projects to be delivered for an external stadium or an event or something like that. But then there are other things that come up as part of that where an internal consultant might say, look, I've come up with these ideas that might be using or developing a tool that's being developed in a new way or being used in a new way or is giving insights in a new way. I'm not sure i've seen this before a is it genuine research that we could enhance or develop as part of the company or might even be a value beyond that and then we would take it outside if there's if it warrants it so that sort of discussion is sort of i mean i'm sure it's similar to my is is this sort of our bread and butter is that's actually what it is. By the way, and this is another misnomer before I start to show. I'm never, ever, ever the smartest person in the room. The idea that because you've got a PhD inevitably means your IQ is higher than the consultants in the room. It just means you've been doing something long enough to develop a sufficient insight into that one thing. Let's throw that out the window. Again, it comes back to humility, right? I've been shouted at enough at conferences by smart people that made me know that I'm limited. But the idea that consultants or practice or industry isn't just chock full of super smart, hardworking people who are not always motivated purely by finance. It's not true. And how would you rank the ability to pursue science at industry? To what extent is it different from academia? You both have been previously employed in some sort of laboratories, academia. Steve, you're now in Lund. Mike, you were at Christchurch. Is there a very direct difference between how you did research as a researcher in the university versus how you do it in your company now? What do you mean by science? I'm not sure. Research, okay, sorry. Yeah, because I'm not sure whether I've ever done science. I'm using research and science almost as a synonymous. It's hard to even define what science is. I guess there's the increase of the knowledge of the humanity and everything that goes towards this goal. Yeah, I think there's more research, because you can do research without necessarily strictly following the scientific method, I'm guessing. But I mean, let's not get into that, because that is three other conversations. Sorry, Mike, you were talking. The capability of doing research as a researcher, do you see any significant differences? Like, it was easier, it was harder. I'd say it's different, right? So you've got different drivers. So, for example, you've got the driver of a university wanting publications and reputation and those sorts of things. You know, that Canterbury, they have the assessment system, I can't remember what it's called now, but here in the UK, I think it's the RAE thing. So you've got your scoring and, of course, there's a metric, a KPI, whatever. So you are somewhat driven by that. Obviously you've got students, and you're driven by their interests, their capabilities, and that sort of thing. So sometimes you're directed because of those. And there's resources as well. so I was very fortunate to have laboratory facilities at the University of Canterbury which have been abandoned since I left I had a couple of really good technicians who I'd go and chat to and build a widget and we had a lab and we'd do things which I can't do now, I've got no lab and that, so was it easier before or it's different, when i was doing my master's at maryland the way of engaging technicians to build things was different they had a as i recall a more central resource so so it was slightly more complicated one might say to get something built there because you had to go to the central resource rather than having someone you could just go and walk down to the lab and say can you build me a so-and-so and they'll go yeah we'll do it like this and i'll get it to you it's done but tomorrow if you need tomorrow and go well next week's great so i can't say what was easier or harder because it it depends it's different yeah but the differences can be quite subtle right and very much sensitive to where you are. I think some academic spaces could be extremely hierarchical, and your direction is governed by the group or the department or the subject matter focus, and, of course, availability of funding. So in government, it was more like someone comes in with a problem. Someone from the public comes in with a problem that then determines whether your unit has to provide some evidence and generate some research to work out what's going on. So that was quite reactive, I think. Lots of resources, labs and access to lots of building facilities that we would never have had access to. In industry, I think the great resource we've got is just a lot of people that can do the thing. So there's a lot of consultants, practitioners, who are not, this is by no means a criticism, they're not new students coming through. They're practiced in the field. And so where there's value to the old researcher, I include all myself in there, is that they become unbelievably useful resources. So they are, and willing resources, they know enough about practice to know how the data that you're collecting might be used. And so, of course, you still have to have that research overview and you still have to have a structure and methodology that can be attacked academically and in peer review. But they then become a huge resource in actually doing the research activity. And so I think that's what's astonished me. And again, we were involved in the pandemic work and we deployed tens of people into the field, dozens of people into the field, dozens of people into the field, that would have been very tricky if it had just been a university doing it. We just wouldn't have had the numbers of people capable of doing that. So there are very few departments that large, you know, that you could just manifest 10, 20 people to go into the field and do an observations. I think it's complicated. I don't think it's necessarily different in one particular way. I think it's very much sensitive to the institution, the academic institution and the industrial institution, the government space you're working in. As I say, I think the main difference is often the speed of delivery, speed of turnaround and the resources available do that. I don't know if that's constant between the three domains, if you like. I think it's a very interesting discussion and it's clearly showing like to anyone wondering if you go to industry you will be thrown on endless loop of similar commercial projects endlessly. There's also a pathway in industry where you can do interesting research, maybe the most interesting research, and focus on the meaningful aspects of that research rather than struggling on which journals you choose or which impact factor metric you have to achieve. That's a trap in academia. Sometimes people also, like, they would have this view that academia is ultimately good or a beautiful, fantastic place where you do research, enjoying yourself, smiling in the lab while... There's a reason why 70% of postdocs have a depression. Well, it can be not a very collegiate place, right? Because it's very competitive. The idea that academia is not competitive, I think, has long gone. I do think the downside, if you're a careerist, if you're really interested in climbing the ladder, operating in more than one space can certainly mean that you don't focus on those metrics within a space that really matter. And so, you know, if you want to get on in certain universities, then you have to hit certain publications and you have to so you know if you want to get on in certain universities then you have to hit certain publications and you have to you know you have to really focus in on on those things and being more of a generalist in terms of the domains in which you work means you just don't focus on that you're looking at multiple impacts across domains and so you're never going to be as successful necessarily by this magic right that's right you're you're you've got like a seven out of ten across three different metrics rather than a ten out of ten on one and so you have to be able to swallow that a little bit that the people will race past you in one area you know there are people that were colleagues of mine that have just gone way beyond me and up the academic scale or, indeed, way beyond me in the industrial hierarchy. That's just how it is. That's just the nature of it. And they were better than me anyway, but that's not the point. If I was equivalent to them, I wouldn't have gone so far because of the more complicated path of being one thing inside another thing. From my side, I wanted to do this episode to see how the other ladder looks like. I know how the ladder of career in academia looks like. I think I understand how the research is done in here. And then I see people from this other ladder, from industry, making true impact, making research that's groundbreaking. I wanted to understand why they would be making it and why it is very attractive for industry to put all the money on the table and do research. And I also think it's fundamental for the growth of this discipline for multiple reasons. One, the funding. Two, shaping the environment and knowing the problems three having access to this what you just said steve the amount of people the tools being able to focus in your efforts change your goals as you grow i guess you also have bigger uh ability to do that when you're driving your own research. It's been a very interesting discussion. I'm constantly embarrassed by how good and how hardworking my colleagues are. There's no sense of, I'll come up with something in a discussion and I'll say, oh, this tool would be useful or this bit of work. One of my colleagues will just have done it because they're industrial park consultants colleagues will just have done it because they're industrial park consultants, and they'll have done it because it's something of interest to them. The idea that, and this is in an engineering environment, of course, but they're interested in the thing. They want to do it. It's not just about getting on and some sort of rat race style. I think they actually want to, they're as interested in the topic as I am. And they just happen to be 28 and able to work all of the current tools that are available and willing to dive in and do the thing. And so yeah, I have to be careful what I say because it will be, someone will pick it up and run with it. It will be used against you for sure. It's a problem, yeah. get up and run with it. It will be used against you for sure. It's a problem, yeah. I think it's interesting that it's very dissentist, again, this sort of utilitarianism. People do it because they're told to do it and they're paid to do it and that's the reason they do it. But people do all sorts of things. Look at all the stuff that people work in, open source software. And they do it as a hobby and they do it as a hobby and they do it as because people are interested in it and sometimes they do it is because it intellectually engages them and they're interested and and all those things and some might say what do i do research and why did and for me it's part of it is to do with that intellectual engagement and i think steve's already talked about the fact that you can work with other people and share that research pathway i mean do it doing it sometimes by yourself it's not it's not that interesting it's just when you've got someone else to bounce ideas off and discuss it and they you know they'll challenge you whatever that in itself could be a reason to do it because it engages something in you that that that you want to engage in and And I'm not going to get into why one does fire research, and is it just a process of research rather than a particular topic? For some people, it might be the topic is of interest. For some people, it's just the intellectual engagement in something, irrespective of what the topic is. I think there's all sorts of things that people do things, and yeah, they need to earn money and pay a bill. I expect some people do it because they want to be seen to be an expert in something. They get something out of that as a measure of their success. People like to have measures of success, and some people's measures of success, and you see it for maybe some billionaires. It's just the fact that they don't know i'm not a billionaire and i never will be but maybe they don't they don't earn money to as a way of so they can buy more stuff it's a scoring system yeah they can measure their success against another and maybe you know some people in research do it for publishing papers as a measure of their success a metric i expect you know as humans are is an element of of metric yeah we do it we know sport you know it's a measure of metric is that is my team better than your team can i run faster than someone else what's the utility of it? Well, the utility is a human competition, you know, survival of the fittest and that, the sorts of things that drive us. I do think that it's not a neutral process. You know, the publishing and sharing and being, it's uncomfortable, right? Because you are being scrutinized. So it's not trivial. I mean, one thing I do, I enjoy the process of working with people on papers. I really enjoy it. But within the topics in which I have something to contribute, you know, it's not just to solve a challenge. That's not the challenge of it. It's not like a word or exercise to me. I want to do something that produces something of use. But it's uncomfortable. But publishing for me is uncomfortable because at the end of it, someone's going to read it and they might really disagree and they might find something that they can tell you and say, well, you should have done it this way. And then you think, oh, blimey, I should have done it that way. They're right. So it's not a trivial exercise. It's not a trivial thing of a marketing exercise for your own pursuit i think it can be very tough and so yeah i mean but i do agree with mike in that you know that people have different motivations i think the easiest one is just the adage of doing no harm is definitely a good starting place i'm trying not trying to and that but that's non-trivial i mean because you don't know how your work's going to be used you know because most work can be flipped over and the phrasing can be used in a different way or something. Yeah, I've seen that. Like I say, you don't know how it's going to be used. A lot of times you don't find out. Again, it was useful. I mean, you can find out when people have – you can go to your Google Scholar and see how many citations you've got in your account. What you don't know is whether, you know, let's go read the paper, the citation, although most of them might say the work by a spin point citation is a load of rubbish. It's a citation. It's a citation. But you don't know where it gets used elsewhere. And I do remember at least one time when one of my students at Cadbury had done a thesis of something and we published those as PDFs. And then I got an email maybe a year later from a consultancy company who said, oh, that's a really nice thesis. It's been really useful. It's nice just to get the sense that someone actually found it useful. Now, I wouldn't have found out had I not got the email, but someone took the time to at least sort of recognize that there was some value in that. And, you know, that's kind of nice. Because it is scary. It's scary, publishing. I don't know if you've seen it. It's scary. I'm scared because it will show how incompetent I am at something. I've made mistakes or whatever. Because we're all limited. You know, we're all limited by our capability to do something. In other words, you know, I can read a paper or read something and go, I just don't understand it because I'm just not clever enough. And there's only so many hours in the day to, you know, there's always that feeling of I should have read more papers. I should have read, I should have dived into this more and dug into it. But you can't do it. And you always think, well, maybe I missed something. You know, maybe I've turned over all these stones, but I just didn't turn over the right one and had I only spent another day and had I only spent a bit longer I would have found something that whatever wait a minute oh that's really and someone else will send me an email and go didn't you read the paper by so-and-so and I go no I didn't I just didn't know it was there I didn't look but that's so healthy right that that doubt is healthy because if you don't have that doubt, then you can get into a lot of trouble because you think you've got the answer. And almost certainly you won't. A, there isn't an answer. And B, you probably haven't got it. If there was. But one thing, bringing it back to the industrial element, I think, which is to what Mike's saying there, which is you often don't know in a purely research setting. Well, we, you know, and again, I don't think we operate in that realm, you really don't know what the impact of a piece of work might be. In a lot of the work that we do in industry, I think, the horizon's nearer. So you have a chance of affecting something almost within the life cycle of a project, unless you're doing more traditional research within industry, which we definitely do as well. But sometimes you see the positives and negatives of your work right in front of you. That's a different sensation. You know, you answer that doubt that Mike's talking about there, which is what would the impact of your knowledge? What was the impact of your findings on this thing that's being built or this thing? I did some work years ago on the Statue of Liberty, and it was was very much that you know what what is it going to reopen or not is it going to you know you often you often work on projects and there's there's a modification to a building and you think i hope that that works i hope that you know i hope that that bit of research that we did in support of this engineering project was the best that we could have done. Okay, guys, I need to stop you there. I can imagine you can go for another five hours on that. This is every meeting with me and Mike. It has been a super interesting conversation with the experts who are researchers who claim to not do science, but they actually do science. Mike, you are doing science. I'm sorry. I'm sorry. You are. Guys, thank you very much for science. I'm sorry. I'm sorry you are. Guys, thank you very much for this. I hope it was interesting to people, to researchers. I hope it was interesting to the society. I guess people are either going to hate or love this episode. We'll see. Well, ironically, we might or may not find out. Ironically, we might not. Well, ironically, we might mail Nevin a find out. That was awful. But maybe they can send me an email that says I listened to it and it was awful. At least I know it was awful then. Okay, if you found this episode awful, please send an email to Mike. In other cases, send it to me or Steve. I only want to hear positives. I don't want him on here. Okay, guys. Thank you so much for being here with me. And yeah, have a great year 2023 because I assume it just started. Take care, bro. Thank you. Cheers. And that's it. Thank you for listening. I hope we didn't bore you down with our amateur philosophy thinking stuff. But I was very happy to be engaged in such a discussion with Mike and Steve, who are industry legends. It was a pure pleasure to hear their thoughts about why we do research and how we do research and how does one do research in academia, how one does do research in industry. Very intriguing. And I think the differences are much smaller than I've expected them to be. I don't think we found a single massive discrepancy in how would you run research in one part or another. We didn't touch that much utilitarian aspects of research as in product development and all R&D research happening around, but maybe that's a subject for another discussion. Anyway, thank you very much for listening to this podcast episode. I really hope you've enjoyed it. Thanks a lot to OFR for sponsoring the show once again. Super happy to have OFR as the diamond sponsor of the Fire Science Show and the collaboration that's going to last for at least one year. That makes me very, very happy. And that would be it for today. It's not the end of the podcasting this week because there's an upcoming Q&A episode. I think it should air on Friday. If I miss it, it may be Monday, but I'll do anything I can to have it published on Friday. So you'll learn a lot about the listener experience survey and my observations from that. And I will tell you what you are thinking about the podcast. So that's very exciting. And I will also share more details about the OFR collaboration and how it's going to affect the podcast and everything I'm doing here. So if you're interested in the podcast itself, you're very welcome to join me. And if you're interested just in the great discussions with leaders of the industry, you're very welcome next Wednesday when I'm having Dr. Adam Barov from UL FSRI to talk about battery fires again. So cool. I'm really happy to do this subject again. And it was a great conversation. Cannot wait to publish that one. So thanks for being here with me. See you for listening and see you soon.