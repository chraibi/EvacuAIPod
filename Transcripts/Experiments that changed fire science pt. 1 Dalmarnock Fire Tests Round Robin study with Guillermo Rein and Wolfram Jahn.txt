 Hello everybody, welcome to the Fire Science Show. Nice to have you here. It's going to be hard to beat the last week's spacecraft fire safety episode, but let's give it a try. Today we're starting, let's say, a mini-series in the podcast. I'm going to make a group of themed episodes. They will be themed around the experiments that have changed the fire science, which means I'm going to discuss here the most impactful experimental programs we had in the fire science, which means I'm going to discuss here the most impactful experimental programs we had in the fire science with the scientists who have performed them or ones that are very well informed about the course of the experiments. We're going to talk about their legacy. We're going to talk about what happened, what led to these experiments, why were they needed, what were the ideas when they were conducted? What questions they tried to ask? And in the end, what did they change overall in the fire science? And today we're starting with the first one. It's on the round-robin part of the Al-Marnock Fire Program. For me, it's one of the most influential pieces of research that I've learned during my career, and they have really laid a new perspective on using of numerical tools, models, the difference between modeling and model, something that from my own perspective, from my own career, has really changed the landscape of use of modern tools. The Del Mar Nocafire program was carried under the supervision of Professor José Torero by the University of Edinburgh, and it was obviously much bigger than the part that we're going to touch about today. It was first and foremost motivated by creating more visibility for fire profession, fire engineering profession, by making a documentary, Skyscraper Firefighters, that aired on BBC2. And that was a major thing to produce a large documentary about compartment fires. And that goal was suddenly achieved. It was also part of a fire grid program, a much larger study. It had massive instrumentation. All of this you can find and read. instrumentation all this you can you can find and read but here today i would like to focus on one let's say little aspect of this experiment and that was the round robin round robin was an attempt to send data to some fire modelers who would try and predict what would be the consequences of the fire in the building then they they've burned the fire, and then they've compared them. And, oh, boy, it was interesting to look at the data, and that is exactly what we are going to talk about today. I've invited Professor Guillermo Reyn, who was the lead scientist behind Apriori, the before-fire-experiment round-robin, and Dr. Wolfram Jahnian who at that point was leading the post-fire modeling where they tried to improve the quality of modeling and predictions given the knowledge gained from the experiments so i hope this will be interesting to you i've linked the dalmarnock papers in the show notes, so if you want to learn more about the experiments themselves, the motivation and the other aspects of it, you're very welcome to do that. There are the Round Robin a priori and posteriori papers as well. A lot of knowledge, very fundamental research, and now let's hear from the scientists why was it important and why you actually should read them. So yeah, let's spin the intro, let's hear from the scientists why was it important and why you actually should read them so yeah let's spin the intro let's go welcome to the firesize show my name is voj're going to try something different discuss some of the most famous, most impactful experiments and papers that happened over the course of the decades as fire safety engineering was developing. And to start it off, I have one that was certainly impactful for my own career as a safety engineer. was certainly impactful for my own career as a CFD engineer. And that is the round-robin part of the Dalmarnock fire experiment. And today I have with me two lead researchers of that task in that big project. First, Professor Guillermo Reyn from Imperial College London. Hey, Guillermo, nice to see you here for the fourth time. Thank you, Boje, it's great to be back. I'll have to buy you like a t-shirt or something for the fifth one, I guess. I would love a t-shirt or a pen or a book or a sticker. I'll figure out something. But it's great to have you. And Guillermo, you were leading the a priori part of CFZ experiment there. And I also have the head of the Aposteriori Round Robin pod, Dr. Wolfram Jan. Hey, Wolfram. Hey, how are you, Wojciech? Nice to be back. Nice to be back. Yeah, you also have been a guest on the show talking about CFD, which perfectly ties to this. Yeah, I think I mentioned this in the previous episode as well. If you have not heard the Wolfram's episode, it's very impactful and you should just pause now. I think it was episode 14 or 15. You were a very early adopter of the show. Thank you very much for that. Both of you were. Okay, let's jump into the domino because there's a lot to talk about that. So first question, why the hell such a project happened? How did we end up having this massive set of fire experiments in residential compartments carried out in what was the grand idea i know that from the talks we had before that round robin came to the whole program at some point of its development let's first talk about why we needed dalmarnock in the first place yermo you were there observing it firsthand. Yeah, so the Dalmarnock experiments of 2006 is the brainchild of Professor José Torero. He was at the University of Edinburgh at that time. And he convenes the housing authority in Glasgow, the Farby Gates, and the TV programmers of Horizon Show, which assigns documentaries, convenes the three of them to have these experiments in a real building, in a real apartment. Not in a real building, but it was only two apartments, two flats that got on fire. And he made this opportunity an incredible and super exciting opportunity because they remain the most densely sensed experiments conducted to date in far science. And this was done in 2006. And it's not been beaten yet because the amount of sensors of all kinds that were inside those two flats is incredible. Many things happen in Al-Marnouk and afterwards. But one of them, one of the things that happened, the one that you have invited us to talk about, is the modeling exercise around Al Marnock. And at that time, Jose and I were in very active discussions about what is the difference between a model and modeling, right? So we both are scientists and engineers, and we were concerned that if one says I've validated the model, that doesn't mean that the modeling applied by another person in another context means that the same level of accuracy or precision is applied. And we didn't know how to make this point. And I remember we had a meeting in London with top engineers and top SDS developers. And out of that meeting, I told Jose, look, there is a way that we can address this. We can do a round-robin. And at that point, Jose said, what is that? And I explained to him the idea, which I guess your audience wants to know as well, what's a round-robin. And a round-robin is when you have a task for a group of people, and everybody does the task independently, and then you put all the results together and you compare what the group has done right so the key is that they're independent it cannot be that i'm looking into who's at the left or who's in front and use that results to guide mine so they are independent then you put them all together and you compare them you have do a benchmarking of one to the other so we said said Dalmarnock is going to happen. We tell everybody, all the modelists around the world, what Dalmarnock is going to do. And before we do Dalmarnock, or before they see the results, actually, it's more correct to say before they see the results, we tell them to simulate this. The development of the fire. The way they want it to do, they should simulate this before they see the results. And that's what we call the a priori round robin, a priori for the Latin of ahead of the event. So before the fire happened, many people around the world tried to simulate with different software tools what would have happened. Then they send us the results. So they send us their predictions and then we send the results. And then the second part is what Wolfram led, which was the a posteriori, or the Latin of after the event. Which was not around Robin, actually. It was just me. Which was not around Robin, indeed. Good point. Why is that? It was just one team, me and Guillermo, basically. So it was just one team. It wasn't many teams kind of competing to do it. I think there have been more attempts of modeling that, but I don't think any of that has been published. I think ours is the only one that was actually published. This is important, Wolfram. This is really important. Why they didn't publish? Because it wasn't easy, even knowing what happened, it wasn't easy to match the results. It was very, very hard, actually. This is the key. This is why we did the Brown-Robin. This is literally why we did it. Because you go into the literature, the scientific literature, and there's this massive filter in the scientific literature that only if you get amazing results, you publish, you submit to a journal. I mean, you have to be out of your mind really to submit to a journal an exercise where you prove you are useless at simulating the experiment however editor please everybody should know how crap i am at modeling so that's why in the literature you only see beautiful examples of cfd or any it doesn't have to be a cfd because this happens to every single discipline known to engineering is you publish only when the results are amazing in your modern exercise you don't publish negative research negative research doesn't have good press doesn't create careers it doesn't take the time of editor so with round robin what we wanted to say is like well a group of people known to the field are going to try to do this the experiments are are amazing and well done. Some of them would not do too well. It will be negative research for them. The other ones hopefully will do well. That will be positive research. Altogether, we think this is something that everybody will want to know about. And that's what we did. We wanted to see the part of the filter that never gets to us in the literature, which is the attempts that fail to simulate what it was attempted to do at the beginning. I think we have to come a little bit back to Wojciech's question from the beginning, that why were these experiments done in the first place? It wasn't about modeling in the beginning. It was about somehow being able to predict the fire based on, because it was all in the context of this fire grid project. The big idea was to be able to predict FHIR development based on sensor data and trying then, once you have the prediction, trying to manage the FHIR. That was the whole paradigm, I think. And at some point we realized that we need modeling, but we can't do it. And that's basically the ongoing problem. It's been 15 years, and there's been lots of development in many aspects, but some of the main conclusions remain. We still can't do blind predictions. If I ask you to move back in time 15 years ago, how did the modeling look back then? I mean, what version of FDS we even had? Was that this four? I did the posteriori modeling with four and i was criticized i'm not using five and so really it was about that time that five appeared okay and the papuary was was four then one thing because we just did something that i did it as well and we should not do the round robin is not about fds okay yeah it's about c CFD. And the round robin actually includes at least two zone models. Okay. And this is important. When we invited people to participate, we did not hint it nor impose any model choice. Okay. We said the model that you are comfortable with. What happened at the end is that the brave, I call them the brave because they're very brave. Only the brave or most of them chose FDS. because they're very brave. Only the brave, or most of them, chose FDS. No one came with the guts doing ANSYS, nor Fluent, nor SOFI. None of these modelers had the guts to come with us to the round-robin. Only users of FDS and this own model came with us. Actually, the two models that were used, 100% of the models used in the round-robin were by NIST, given to humanity for free. Nice. That's powerful. And what was the environment back then? I guess this was quite soon after the World Trade Center papers were published. Also, this investigation is also something that I need to cover in this series because it was also groundbreaking on its way, and I know it paved the way to multiprocessor FDS and other things that we take for granted today. Like, it's obvious they are here. But then it were problems. From your experience, how did it look back then? Well, in terms of modeling, what generally? Yeah, yeah, yeah. Tools of availability of solutions, of the best practices. That's a good question. I think there was a little bit of – so there were these paid to convincingly to reproduce the viable of the World Trade Center. You remember that. So I think there was a bit of feeling that, as we discussed before, I think, that kind of modeling, we could model FHIR. It was possible. We had the model that was FDS. It worked. And actually, it did work for some applications. It worked very well. There was quite a bit of validation of the model. So it had been validated, and it worked. So I think it was a very positive feeling that we basically, there was a very positive feeling. There was a managed problem in a way. And I think that the big problem is actually a difference between I always say that fire modeling and fire consequence modeling. And I think that's the key here. So you could, back in the days with FDS4, you could very well model the smoke movement if you had the information about the fire, the heat release rate. And I think that's the key, because that is what they didn't have for the round robin. They didn't have the fire. They had all the information to create the fire, because we gave them, well, the amount of testers. I wasn't there at the time, and I missed them by a week. They gave them all the information, but the fire development couldn't be done, even with all the information, not blindly. Yeah, but Wolfram, just to highlight that this is a, we know this now. Oh, yeah, yeah, yeah, that's what I'm saying. This is what kept us busy, we published the paper, This is what kept us busy. We published the paper. This is what kept us busy with reviewers, that the reviewers were either saying, this is the best thing that I've read in 10 years. And the other one was saying, this is the worst thing I've read in 10 years. Our editor was Professor Dougal Drysdale, who is known to be tremendously fair and dedicates time to the process. So just to give you an idea, we published the paper, right? So we get comments, and we end up rebutting for twice the length of the paper. So you have the paper, which is a big paper, and the rebuttals with all the reviewer comments, only half of the reviewers wanted rebuttal, lend that to twice the paper in thickness. So actually, we end up writing more to rebut the reviewers than the paper itself. Yeah. up writing more to rebut the reviewers than the paper itself. Yeah. That must have been. And I think, you know, I wouldn't say a lifelong struggle, but a little like a career long struggle is to convince people the problem is not the model, as Guillermo said at the beginning. It's about the model or the modeling process. FES or CFAS for that matter, They are perfectly well suited for certain purposes, but you have to know which are the, you know, what they are designed for, and then you can use them. But so when you criticize the modeling process, it shouldn't be understood as a critic to, or criticizing FDS, or whatever other simulation you have. It's about the modeling process. And that's actually what came out as a result of all this, is that we have to be conscious about that process and where the limitations are. And I think people weren't conscious about it. They didn't know. Okay, so to give probably all the people in the audience may hear the word Dalmarnock for the first time in their life. So let's give them a short introduction to what the fire did look like. Like, what was actually the thing burning in the experiment? Of course, the experiment, you have to give the credit, it was a much bigger thing. Ron Robin and the CFD part is a part of it. And there's a website of the project. There's many papers to be read. There is the documentary TV, which you've mentioned, Guillermo, and I now need to find, to link to the show notes. If I find it, it's going to be brilliant. If I cannot find it legally, I'll steal it and make a copy for anyone, for the glory of fire science. I have a copy in CV. Okay. If it's the last resort, I have a copy of it. Fantastic. I have no remorse. I live in Poland, no worries. I can steal that. Put it in the internet for the benefits of fire science. I think it's actually important to do that. Anyway, it was a huge project, but let's talk about the part that touched myself, which is the round-robin and the posteriori CFD part, touched myself, which is the round-robin and the posterior CFD part, because we've talked about it for years, about the reasons of the project. And there's a reason why inviting you here, I had the CFD part in my mind. I think this was something that if you ask a random fire scientist about Dalmarnock, they would probably refer to this part of the experiment. Because it aged the best of all of them for some reason. Now, let's go back to, I have asked you a question. What was burning? So what was the fire load in the Dalmarnock? The objective of Dalmarnock was to have a real fight, not an experiment in a laboratory with a fake fuel or with a made up fuel. No crib. This was an attempt to do, I mean, there were already a few experiments of NIST and other people wanted to do one British style, so to speak. And it was a flat, a small flat with two bedrooms, one kitchen and one living room. Remember, the Belmarnock includes two experiments. I'll just focus on one is the same. And most of the action by far was in the living room. The living room had a sofa, had two bookshelves, had a table, had a desk with a computer, with a chair, and it had a little bit of decoration and there was a blanket on the sofa. So it just tried to imitate a normal living room of a modern flat. Every single element, except I think the computers, were from IKEA. And we actually even have the names of IKEA and the year of manufacturing. So it allows some repeatability, so to speak. And if you see the photos, it looks modern. It looks very IKEA. The only thing is it's absolutely a pack of sensors. There were sensors for the smoke that stand layered with lasers. There were strain gauges in a replica of a steel strut like in the wall to the center. There were thermocouple wires in the walls, in the center, heat flux meters everywhere on the surface. There were cameras, CCTV cameras. There were small detectors. It was pack. It was incredible. It was very exciting. You can imagine the amount of data that was produced out of those two experiments of 15 minutes. We still have not processed all the data. It will never be processed again. That's beautiful. There were some experiments previously to the big tests. Basically the sofa was burned, I think, under the hood. So we bought three sofas from IKEA. One each of the flats received a flood. Four. Okay, yeah, it's true. What happened to the fourth one, Wolfram, is not official. Yeah, so the three that I know, one of the sofas was burned in the lab under laboratory conditions. No walls, no environments, under the hood. And the idea is to measure the heat release rate. And we measure the heat release rate and we provide the heat release rate to the round-robin participants. So it's not that they have zero knowledge of what was going to be the fire development. It's that we said, in the lab, this is how it burns. Free burning. No smoke layer built up in the room. No walls. No radiation. And the question is, with this information, how do you think it will behave if you were to be in a room? Yeah. But there was a difference, though, because during the tests, there was a blanket. So there was a waste basket next to the sofa. That was the ignition source. And the fire should spread to the sofa, which it did under the hood. It worked, but it took quite a time. So during the experience, to make it a bit faster, I think they put a blanket over the, hanging into the basket and kind of over the sofa. So that was kind of a great... And Wolfram spent a significant amount of time simulating this. Yeah, trying to figure it out, because that was actually, at the end, it was quite important. Which is, again, one of these things that you wouldn't think about beforehand. That was, during the pre-flashover, one of the most important bits of information. And you say, well, you didn't, so the round robiners, they said, well, you didn't give us this information. Well, yeah, but that's part of the, no one knew that. Like, when you design a building, you don't ask where the rug will be lying, right? No, but this is important. The thing is, we can tell the story from as it was happening or afterwards. Because remember, the Wolfram spent half of his PhD doing the posteriori. The Wolfram is telling you 100% the truth. It took him three years to figure it out. Two years was trying to get this published. It was just one. Yeah, it's true. Because we met reviewers, opinionated reviewers, also with the posterior. I spent the better part of a year trying to figure out why this was so different. Why it just didn't match. So it took me a year to match this. And at the end, it was as simple as that. It was just a blanket. No, but wait. I want to frame this because I know how history can cast this. So it was the blankets, okay? The blankets happened to be absolutely essential for predicting better the fire. The thing is, this was not known to absolutely anyone. So it's not that we did it on purpose. Oh, the secret blanket. No, we have absolutely no idea that we were doing this by putting a blanket. And the second one is, if the blanket changes the results from, I have it here, from 500% wrong to 20% wrong, then we are doomed in fire modeling. So I happen to believe that that's not the case. I think that there are details that matter and there are details that do not matter. And obviously in an immature science like fire science, we have a lot of work to do. But what we should not be doing is we should not be saying the blanket doesn't matter. That's not true. And we should not say the blanket is the only thing that matters because that's not true either. So there is a context. And in fire science, we are dealing with such a complex phenomena that we cannot just focus on one element. Unfortunately, we have to focus on all of them at the same time and decide little by little which ones count and which ones count less. I'm looking at a picture of the room right now in front of my eyes. There's actually a 33 pages long paper about the instrumentation alone. Give an impression about what scale of instrumentation we're talking about. I'm looking at the room. There's this couch with a blanket. There's a blanket. There's the three wardrobes with some papers on them. There's a computer desk, too, actually. There are some chairs, computers, like the random stuff you would find in an office, a plant, an IKEA lamp. I had a lamp like this. I confirm that's IKEA. an IKEA lamp. I had a lamp like this. I confirmed that it's IKEA. So, indeed, a very normal space, an office space that you have in a building. So, let us go round-robin now. What exactly did you give? Everything. So far, we hit release rate, but what else? We gave them photos of every single one of the items independently and together. We gave them photos of every single one of the items independently and together. We gave them the catalog description of IKEA. It actually even gives you the materials in IKEA. They could actually go to their local IKEA if they want and buy the same version of the element if they want. No one did this, but they could. We gave them, we weighed some of the materials. For example, the sofa we weighed. We gave them the heat release rate of the sofa burning the lab. We actually, when we did the experiments, we realized we never thought about this, that there was press coverage. We didn't think about this for our own growing. And we thought, oops, then some modelers might be good with social media, how to speak, and might actually have seen the coverage, right? Because at that time, to tell you the truth, we didn't know if it was going to ignite or not. Obviously, I can tell you that no hotel trailer had that many fires, so it was probably going to ignite, but we just didn't know if it was going to ignite. I mean, is the fire going to spread across the sofa? So anyway, because it was press coverage, so we knew there was a fire, so we had to take our copies of the press coverage with some photos of the plume from the outside. And we gave it to everyone. And we say, oh, by the way, and the window, there was two windows. The second window was broken on purpose from the outside. It was Jose Ferro in a stone. And we gave them the specific time at which Jose broke the window from the outside. We didn't say what happened to any other window because that was not an intervention, right? So the modelers knew that a fire happened and that the fire developed and there was some plume and that someone from the outside broke a second window. But they knew absolutely everything else that was inside the room. And then we asked them, do fire modeling of this event and make predictions of the following variables. And we said, well, average temperature, local temperatures in a couple locations, smoke descent, heat fluxes, obviously heat release rate, that was the first one, time to flashover. I think that's it, right, Wolfram? Yeah, I think those were the main. Because these were the things that we could measure. We didn't ask them to predict anything that we could not measure. And we said, just send this file. And when you send the file, only when you send the file, we'll send you the data. Okay. So now going into these predictions, you've already teased it a little bit with 500% scatter, but we'll unravel that in a second. It's actually 800. Yeah. Come on. Okay, nice. So first of all, the flashover, it's grown. Okay, nice. So first of all, the flashover, it's grown, the flashover has happened in this compartment and it was like a fully developed fire that self-extinguished. Was it quenched at some point? No, it was fire brigade that came and extinguished. Okay, fire brigade. We were very nervous at some point, I think. Yeah, we've been there, done that. Fire brigades in large fire. They're always becoming nervous at the interesting part for some reason. Anyway, so let's talk flashover, the predictions of the time of flashover. I think that it's for me myself, having the knowledge I have today in terms of doing full-scale experiments. Like full-scale experiments are unpredictable, like absolutely unpredictable. Especially when you model 382 square meter of borax. Yeah, but Boje, I have to stop you there. Yeah? We got this comment very often. Tell me in the literature, scientifically, not opinion, where that is set. I agree with what you said. Tell me where in the scientific literature there is a statement that can be quantified as saying this person is saying that larch ale experiments cannot be predicted no there's none and i if you ask me the question five years ago i would say we have perfect models to predict that and now after doing like 20 of these i have no idea it's so hard to predict now what i want to say is the moment from the moment of flashover to some certain extent of time it becomes becomes more predictable, you know, because then you just have all this stuff burning. And I think there's less variability because you have, it's essentially energy balance from that point onwards. And to some extent, the intensity of radiation inside the compartment, which probably is affected by many things. But from the flashover, it becomes, to me, more manageable. Then again, if I model my shopping mall and I model a flashover mall, I did not a great job as a fire engineer. So I do not really commercially model this. I don't care about the post-flashover fire when designing my smoke control system because that means I failed as an engineer. So I care about this earlier phase. And now this earlier phase, as you said, a dish rack can change the fire behavior and actually build up of the conditions inside the compartment that did lead to flashover. That's an interesting. So this is why my first question is, what was the scattering time to flashover? Because it, in a way, is an umbrella of all the things that happen as the fire grows to reach a certain size. So this is why my immediate first question, not temperature deviation, not smoke layer height. A hundred. It went from a hundred to a thousand to a hundred. Okay. That's a scatterer. And I want to emphasize this, but obviously you can go back to the paper and see the names of the team members, and the great majority of them are really, really well known. These were not amateurs. These were people that at that time and now were very famous and people will rely on them to have views, professional views on fire modeling. Obviously, we didn't get the best modelers or the most famous modelers. Also, I think these people, first, they didn't know us. I mean, they said, Guillermo who? Who is this guy? This guy that just graduated. And also, they had an invested interest because we were going to show the results no matter what. I think you mentioned this. We are not the first round robin in a far science project. We are the first ones to go to publication. There were at least two attempts before us. The results were never shared with anyone because when the room got together, they were so unhappy with the results that they themselves said, they themselves thought, this will damage the field. We cannot go public with this message. And when we did the round-robin organizations, at the beginning, we said, we are not going to back up. Maybe we will not be accepted in journal, but this will go to our repository. This will go to conference. Maybe we are going to share the results of this no matter what. And I think that might have made some modelers uncomfortable that they would not be able to create if things go bad. The best round robin we have right now is a yearly contest to find the hit release of the Christmas tree. And it's fun. It's fun and there's a lot of scatter. I wonder actually if there would be a value of gamification of these round robins and maybe just do them more often without hurting anyone because it helps us understand our profession better. So Wolfram, you said, what was the scatter from 80 seconds to 12? Some didn't, never flashed over. I think the latest one, I'm just seeing the graph here, is about 800 seconds. So it was between 80 and 800 seconds. That's a massive scatter. And the flashover is sensitive to the heat fluxes to ground the smoke layer high to some extent and let's say flame spread over solid surface. But I guess the whole sofa would be in fire at that point. So how would you look for the predictions of the heat fluxes and layer? Disaster. So, I mean, if one goes to the paper, we start with the heat release rate. Okay. The predictions of the heat release rate cover a very wide range of predictions. It's wild. I typically, when I present this, I always say any dynamics possible to the planet Earth are here, predicted. You will have to go to Mars to get a different curve. It's very broad. And then in the middle of it, there was one side that was low. That is the experimental data with massive error bars. Wolfram arrived one week late, so his predictions are not there. My predictions, the predictions of my team are there. We didn't do well. You just cannot tell exactly who is who. You just know that the authors, all of them had models. On purpose, we didn't link authors and names because then it became a different game. So what I want to say is that when I say that the models didn't do well, just letting you know that we were there. I was involved personally in this and I didn't do well. So I feel that I'm fine. And since then, I continue using modeling as an engineer, as a scientist. So it's not that I did this to end a tool of science, quite the opposite. I did this to bring balance to the tool, bring balance to the force. The force was unbalanced, I thought. So I lost the train of thought. Yeah, the layer. So let's talk layer heights. In the heat release rate, we didn't do well. And everybody knows that if you're not doing very well with the heat release rates, it's not going to get better. And it is true. It didn't get better. It just started to get worse and worse. The average temperature of a compartment, average of the smoke layer, didn't do well. But it did as bad as the heat release rate. When you look into the smoke descent layer, I know you're very interested in the descent layer is for how long someone can be inside. It was a disaster. Probably is the worst of all. It was an absolute random spaghetti plot of throw something at it. It's incredible. That was probably the most damaging result that we discovered. It's like such an important variable for life safety, the extent of the smoke ledger, and we cannot get it right. Or at least for multiple reasons. It's not our fault. It's not the model. It's the whole process. The colors on the plots are consistent. Like the green group is the green group. So actually on the plot of each release rate, there's the green group who did fairly well on predicting each release rate. Yeah, yeah. Can I tell you the story of that one? This downroaring never ends. So the green team, which I think I remember who they are, but I'm not even convinced, and I lost the email, so I will not be able to tell you. But I remember that the green team submitted this simulation. And a few days before we closed the folder and we said, you cannot submit anything, they sent me an email and said, Guillermo, please, please, we take it back. We want to remove the one that I sent you, and we want to add this new one. And I thought, well, some groups, like actually us, are not submitting one simulation. We are submitting an ensemble saying that anything between these two is possible. And they thought, oh, that's really nice. Yes, and then please add these two. And they wanted to remove the one that they nailed the heat release rate with. The green one? Yes. Okay. My summary for this is not even when we get it right, we know it. Yeah. That makes it even better. What I wanted to point is that they nailed the heat release rate perfectly, but they were among the worst to predict the layer height. You know? Well, the layer height is not the first. That's so fascinating. Like, it's not even about nailing this one parameter, you know, and you are sure your simulation is going to be perfect. It's such a conundrum of different physical things happening, flow rates, velocities inside pressures, so many things that affect your flow. Even the, like, minuscule change in an external wind could turn the simulation around, most likely, and you would never know inside of your simulation. So that's fascinating. And obviously, if you didn't nail the layer height, you're never going to get the temperatures in the vertical plots. It was the other way around. They produced the temperatures. Some people might have done... The thing is, we didn't say how they have to define the layer height. height we said this is how we measure it we measure with lasers and then it was each of the teams to decide well i want to do this with cifas this way with fds this other way so we we were not constrained we were not given tiny little details we were not macro managing the simulations we said this is how we measure to your best. And they didn't do well. Some of them because of the definition of the layer height, but that's part of the problem. I mean, we cannot go back to people and say, don't worry, your building is super safe. I designed it myself with FBS and I'm super famous. And don't worry because I'm the best at knowing how to define the layer height. Like, that's not the point. The point is, it's not how I define it. It has to be how the community thinks is the best way to do it. The collective mind of the fire engineering. And the last variable that I wanted to talk, which also for me is not that huge variable. Like, the time to flashover would be important, and from flashover it goes on in a very certain way. Then after flashover, it goes on in a very certain way. Then after flashover, your ventilation is limited. The size of fire is what it is. The smoke production size is what it is. So in essence, at that point, you should pretty well nail the hot layer temperature because that's basically the heat balance equation of your compartment again. And there's a massive scatter on the hot layer temperature after flashover as well. Because I see groups who never went above to 420 degrees. And there's a group which had 1200. So that's a massive scatter in like the final temperature, maximum peak temperature, which in essence will be highly related to the damage to the structure of the building. No longer humans, but the structure of the building no more no longer humans but but the structure right no absolutely right and and we didn't do well um predicting average temperatures but when we went into the local ones okay important that magna would have the ability to look into several vertical um profiles with thermocouples we did even worse so the scatter is is. One of the conclusions of the round-robin is we did bad in average predictions, but we did even worse with the local predictions. And the heat fluxes also fall into the realm of the local ones and in the well. Now, all this is really sad, but then Wolfram comes in and he was able to improve this tremendously. I mean, he literally turned around everything. Okay. But of course he did it because Wolfram did not submit his papers to publication until he minimized the error between his predictions and the experiments because he had access to the experiments. He knew what happened. So I had all the results and I tried to find the heat release rate that would give me the match between the... Okay. So what we did after that, and that's the fourth so far, is that there was another one burned after. I had two sets of experiments for the heat release rate to choose from for my posteriori modeling. And none of them worked. And they had quite a big scutter as well. I mean, the difference between those two tests in terms of heat release rate was over 200% as well. You mean the sofas burn outside the flash? Yeah, in the color measure. And just to recast your question, you're saying we did not measure the heat release rate in the experiment itself. We could not measure the heat release rate in the experiment itself. We didn't have the ability to measure. We could not measure heat release rate before flashover. We could measure heat release rate after flashover by assuming that all the oxygen was consumed and we had flow meters through the vents. But until flashover, we didn't know the heat release rate. And Wolfram is saying he needed it, obviously, for the growth phase. So he went back to the only two experiments that existed. One I want to highlight. One was official. The other one was unofficial. So we did the second one for this posterior remodeling. So this way, we went... Okay, perfect. So it's not part of the remodeling. So we did this again. But what I'm trying to say is that the heat release rate of those two experiments, only the sofa burning under the hood, were tremendously different as well. And that was when we concluded it was the blanket that made the difference because it kind of accelerated the growth. And it wasn't just the fuel load of the added blanket. It was the increased growth rate of the fire. I have to stop you for one second, Wolfram. When you say that the blanket influences it, you meant the growth, the speed, the time to reach the flashover. But the blanket had no impact that post-flashover temperatures. The blanket had no impact that smoke layer heights. So it's important to... Yeah, this was all... Let's not give an impression that the blanket broke the modeling. It's a tiny variable, yeah? And that was a tiny blanket. I mean, it wasn't... This happens to all of us, right? What takes us the most time is the one that we want to talk about most. The blanket was a big thing for Wolfram, and actually was a breakthrough when he was confirmed. And I want to say, this is important important he confirmed this scientifically yeah it's not that he had an opinion which he obviously has it he scientifically can prove to anyone that wants to listen to him that it was the blanket that offset the growth phase and the growth phase means the flashover happens later it means that the time of burning is different i mean if you don't get the the time to go right then everything changes yeah so it's very sensitive to that yeah so we have these two sets of experiments as an input for our models so now we have the and none of them work so we as i said we started to figure out how to you know how to model this by comparing temperatures and came up with the blanket at some point we found a heat release rate curve that included this blanket, which we didn't have the data for. It was a kind of an – we just knew that there was a blanket, and we recreated this. And then we suddenly were able to match temperatures to a very good degree. And by matching means you – like this is the 20% point, the one where you almost got it, right? Yeah, so we matched average temperature in time, so we had time-temperature curves that matched satisfactorily, and then we had at certain times where the, you know, basically we selected certain points in time where the average temperature in the compartment that we simulated was very close to the one that was measured. And those times we compared the local temperature distribution in height and space, basically, and it was consistent. So we had good results, obviously within certain ranges, but's say, but we had good consistent results with that. So again, I think this is important to say that the model that we used in that case, and in this case it was FDS4, once we had the heat release rate and we had mastered that bit, we could actually make good predictions. And which says, okay, the model is not the problem. So we can kind of predict the demand of hot air and, you know, gases once we knew what drives them. So I guess that was a relief moment for modelers. They all be happy, but they weren't. It took us quite a bit of getting this published. but they weren't. It took us quite a bit of time getting this published. Now, looking at the results of your post-triori study, which is interesting, I see that the heat release rate is fairly close match. The temperature, I assume, the average layer temperature is pretty close match, at least for the most of the simulated time. But individual profiles are still very different and different in a peculiar way that in some cases, yeah, in some of them, especially the ones nearing openings, doors and the windows, where in simulation you would have actually observed two-layer behavior and in measurements you like it seems like a layer and a strong flow on the floor. Yeah. I mean, yeah. But he reduced the scatter tremendously. If you read the two papers together, the improvement is tremendous. So it's something that I want to highlight because I know how history is written. One of the reasons why we wanted to do the round-robin, my main objective, actually, is something that is modern now. You know artificial intelligence. Everybody's talking about artificial intelligence, not in far science, everywhere. And they say they have a replication crisis, right? That no one, most people cannot replicate the studies of the other. Well, I had a replication crisis of my own. When I was studying CFD, far modeling, I thought I could not replicate most of the results that I was seeing from colleagues in there in papers, in papers. This is very important. No, I was seeing these beautiful papers with these beautiful predictions of the experiment. And I was trying myself and it was crap. So when I was, I was obviously telling to myself, Guillermo, that's because you're a crap modeler. And then when I was talking to some people, some people said, actually, yes, I confirm this is because you're a crap modeler. I thought, are you sure? Are you sure? Because how come all these beautiful papers are published and so few people can replicate the results? So I do think at that time that we had a replication crisis as well. And I wanted the round robin of farm modeling to show to everybody that we do have a crisis. And it's not that we as independently aircraft modelers is that fire modeling is even harder than fire science, because you need to master fire science in order to master fire modeling. And fire science is in mature field that is just developing a few decades ago. And fire modeling, although it's an absolutely essential tool that everybody should be embracing, is just not the panacea. It's not just a magic ball that we have, we touch a bottom, and it gives you results. The results look amazing. But that doesn't mean always that the results are amazing. And Dalmar Lock Papers were probably the first ones who shown that on a plate, look at this scatter and tell me it's otherwise. It's so obvious looking at this spaghetti plot that you are just right and i have this experience from the other side from trying to make my experiments as high fidelity as well controlled as i can and then replicate them with cfd and i absolutely unable to do that. Like with colleagues from Ulish-Forschung Center, they were trying to match visibility in smoke with a very highly controlled experiment of n-heptane in a very specific 10 by 10 by 4 meter tall room. And I have good experience. It's one of the most repeatable experiments. It's one of the most repeatable experiments. I can match the temperatures to like 5 degrees Celsius experimentally doing the test here and in Germany. This is how repeatable the test is. I've done it tens of times. And they are unable to model it. They get the error invisibility 500%. Modest error of the most important variable we use for the design. There are people who are trying to model simple heat transfer even, and they're getting errors of 100% because when you really, really want to solve a heat transfer on a vertical boundary and you stop using a Nusselt number of whatever, 25, sorry, the heat transfer coefficient based on whatever you have, but really determine what is the value of heat transfer coefficient. Here you go, scatter of 300%. The more precise you go with modeling, the harder it is to really nail it, right? Yeah, but I think that's the good bit because that's actually the model, and that has been improving. So I think there's definitely, you know, you go towards something. The other bit, there's some intrinsic problem with modeling because you don't, I mean, there's some bits you can't predict, basically. And I think you have to separate that clearly. So this is, you know, the FHIR models are very, very good these days, but there's still lots of room for improvement. But the input is still bullshit. The fire models are very, very good these days, but there's still lots of room for improvement. But they put the steel bullshit. But there's another bit that doesn't even depend on that. It's just that we don't know what the heat release rate will be blindly beforehand. And we have to somehow come up with a way to model that, and that will influence the results. And I think you have to be very conscious about that. It's not even heat release rate only. There's many parameters. Yeah, but this is becoming set out Celtic for me. So the comment about the heat release rate is 100% true. If we don't know the heat release rate, we are in trouble. And this was one of the main arguments of some of the reviewers that we have to go trouble and this was one of the main arguments of some of the reviewers that we have to go through over months and months of time and at the end we said of course we i mean actually that mark no ground robin shows this that if you don't get the heat release rate right then you are losing tremendous amount of ground to do predictions of anything else but there is absolutely no study in the whole literature where this is shown or said. So this is one of the things where we scientists, when we have a coffee, we are meeting in the lunch of the conference. We all are in agreement, but when it's time to go public to humanity, then absolute silence, right? It becomes like this deep secret. If you don't have the Hillary's rate, you cannot predict. Like, tell them. They need to know. You know, there is a built environment where people live, where the buildings are done with people. So, we tell this reviewer, at some point I will publish the rebuttals. I said, of course, it's true, and you can now cite this paper to show scientifically that it's true. In the meantime, no one could cite anything about it. Can I tell an anecdote that happened to me with the Ron Rowan paper? So we were hired as an expert in a trial. So we did some fire monitoring. It was about showing a timeline in a fire that happened. And there was smoke seen at some point in a camera. And we had to basically come up with the time that the fire started or reached a certain. So it was basically, we had a very good idea of what happened. It was, you know, it was basically smoke movement. So we were quite confident we could do that very well. So in the trial, so I presented my results and, you know, very confidently. So the lawyer, no idea about fire. And she used the round robin paper against me. She said, you said. How dare you use my own spells against me. It was amazing. I wanted to congratulate her because she used my paper to invalidate my expert. Which, I mean, it was very well played. Obviously, my answer was, you know, in this case, I knew what happened, I knew the hit-release rate, and I just was modeling the result. But, you know, the fact that she had researched that and had found me saying that... A small victory, right? So, we are nearing the end of the episode. So probably the most important question, what was the lessons for you? Like, how did it change you as a scientist? Guillermo, you go first. Yeah, it had massive effect on me. In a way, extremely positive. So first, it made my profile visible because so many people had strong opinions about the results half of them hated it half of them love it it was one of these stuff is that you go into a room and the room is not the same afterwards i had to discuss one-on-one these results with many known people and that helped me know them and know their views which is something that otherwise people will have to spend years and years it gave me confidence of the things that I can predict, that I can expect, and that the group, my group can expect from modeling, not just fire modeling, but modeling in general. For example, uncertainty became very important for us, for my whole career. Not only experimental uncertainty, but the modeling uncertainty. The fact that there are some parameters that we don't know, and that it creates uncertainty in your predictions. And since then, in most papers that I can remember, I hope, we have always had uncertainty in the modeling and uncertainty in the experiment, especially when we compare the two of them, right? Because we aim for the intersection of the two. We just don't have a model, one simulation. And also another thing that we embrace with Wolfram actually as well is the value of ensemble. It's not just that we have one simulation, it's that we have a group of simulations and we say in between, most things will be valid because we are just not sure of what would happen, right? And this is something that the word ensemble, the first time that it's used is in Wolfram's thesis, I believe. Before we had the concept, but we didn't have the term. So then we call it an ensemble since then. And your view on engineering through the glass of Dalmarnock, through the filter of Dalmarnock, how did you view the fire engineering afterwards, in which the modeling is such a profound part of it? I don't think it changed it. It created an even discussion. You could see discussions where people were saying authorities and other experts and forensic trials like Wolfram, where suddenly the value of modeling was discussed as opposed to being taken as the top of the science have spoken. As, look, we have this paper here. What do you think of this? So it created more discussions. I don't think it changed. Modeling continued to develop tremendously. Maybe we helped a little bit with a grain of salt to make it more mature, more professional. What I said before is we thought we wanted to bring balance to the force. Seriously, modeling is a force. Obviously, it's one of the three forces of science. So maybe it was a little bit unbalanced, I think, at the beginning of the century, and maybe Dalmarnock helped a tiny little bit to bring balance to the force. And for you Wolfram, how did it change you? Is your PhD thesis so it changed you from master to doctor? Yeah, it was pretty much the same as Saint-Giguiénemont. I think, you know, the round-robin per se was a bit of a curse and a blessing at the same time. So it brought a lot of problems with people. Yeah, because it was always perceived as an attack to the software, which it wasn't. And it's still taking me quite an effort to convince people that I'm not criticizing the tool, I'm criticizing the use of it. So that's, yeah, I think that's the main takeaway for me is that you have to separate these two things. These are tremendously valuable tools and they can be used, if used properly, if used by people who know what they're doing, by people who know their limitations. And I think that's very important to know the limitations and know where to apply them and where to go a different path. Now, talking about this over a decade after it happened, I think more than 15 years since the experiments, it must be quite fun. It's still discussed. It still lives on. It's still... I saw you, Guillermo. I think you had a presentation this year about Dalmarnock somewhere. It's not a legacy, it's part of the shelf. It's still alive in the community. Let me tell you this, it's alive. So last week I gave a talk about Dalmarnock to the Institution of Mechanical Engineers here in London. Now, it's not that they came to me and they said super famous al-marnock speak about it they said do you do you have anything to say and i said yes i have al-marnock and they say you have what i said well let me give the talk and then you know what it create a fantastic discussion so this is this is 15 years old and it create a fantastic discussion in the room only like three people knew knew about Dalmarnock. The rest, the 20 others, were like, wow, amazing, really? And you know, Wolfram is absolutely right. We made a lot of enemies, actually. Unfortunately, in the moment. I think most of them did peace with us at the end. We made peace with them. But in that room, there was no controversy. In that room, when I presented this last month, everybody was like, course oh finally someone says this well no oh great i'm gonna take this to my team right it was all very positive very constructive we didn't get in any of the aggressive response that we got well it is important right because i was a very young academic at that time and wolfram was doing his phd so you don't want you don't want to be the center of a storm when you are in such early stages of your career. And Wolfram's paper a posteriori was rejected from the journal. I had this previous one. We had this one paper where we used Dalmarna beta to assess the parameters of the FDS model. And I presented that at IFSS and the Fds developers were in the in the audience and it was my first it was the first half year of my phd i didn't know much about anything and yeah i had to confront them and traumatic experience but yeah as we are fire engineers and our job is to predict the uncertain future from very uncertain data point, I hereby predict that as we refresh this piece of literature on the shelf, I wonder who's going to be the first to publish AI predictions on Dalmar. That could be. I have my hands. If I had to bet money, there's one group I would bet on. No, you can't. You have to do it ahead of time. So what I would like is artificial intelligence people to predict an experiment before we do it. Just if you can find me. Artificial intelligence are trained on purpose against the results. Of course we get it right. If you find me five groups of AI who would like to do that, or ten groups of CFD engineers who would be willing to submit the results, I have a place I'll find funds and I'll do it. I'll do the experiment. Please don't make me review that. Okay. Now, Wolfram, you will be co-author. You're a professor, now you can send us your PhD students. That's the whole point. And guys, for the very, very last thing, some years ago, 2019 or 2020, I think that was, in the midst of pandemic, there was this FPU Europe conference in which we played a trivia game, and there was a question in the trivia. In 2006, the University of Edinburgh has conducted a series of fire experiments that forever changed our understanding and trust in COD analysis of fire safety. The profound conclusions were related to the scatter of numerical predictions of multiple engineering teams. The question now, what is the name of the Glasgow district that gave name to this program? And there were answers which are Pollockshills, Drumchapel, Woodside and Dalmarnock and 60% of the responders got it correct. I hope after this episode that would go to 90 something. And they could spell it and pronounce it properly you think? If you want more funny things about the trivia we also ask how much the sfp handbook weighs which i saw behind volvrum just a few seconds ago and just and that actually 7.57 kilogram and only two people got it correct so you have to do this trivia again that sounds like fun that was a lot of fun i think can i add one comment that you might you can edit it in and out if you want it's something that okay so i told you can edit it in and out if you want? Please go on. Okay, so I told you the difference between models and modeling for us was really, really important. This has been mentioned before. This was mentioned. Pejora, as an engineer, I don't like that. As user effects, right? So you have the model, and anything that is a screw-up is always the fault of the user, right? So, typically mathematicians say, oh, that's not my fault. That's the fault of the user. But as an engineer, engineering cannot happen without the user, right? So, that's why I prefer, instead of talking about user effects periodically as the people who come to screw up the beauty of the model, I prefer to say, well, there is models, which are mathematically mostly. well, there is models, which are mathematically mostly, and then there is modeling, which is engineering, which is not only science, it's also art and actually protects people from fire. This is something important for me because I discussed that tremendously after the round-robin when eBay was public. People were saying, Guillermo, you just published a paper on user effects. I was like, tell me that again. What do you mean? What do you mean user effects? So it's that. Yeah, beautiful. That's a great, great final thought in this episode. I love this series. I'm going to do more of that. Actually, okay, guys, thank you so much for spending an hour with me. It's a huge pleasure. Thanks again, and see you around, guys. Thank you, Bojay. Thank you. Great to see you around, guys. Thank you, Bojay. Thank you. Great to see you all, Fran. A bravo. Thank you. And that's it for the first episode in the miniseries, The Experiments That Changed the Fire Science. I hope you've enjoyed that. Tell me if you like the format. Tell me if you would like to hear more about these experiments and this research. Maybe you have ideas which to cover next. Actually, some of them are already in production. So I guess if you'll guess up what's the next step for this series, I hope that I'll get some nice recommendations from you. And I'm more than eager to continue this series because I absolutely love learning about the experiments and how the landscape of fire science has changed over the years. This is probably the coolest part of the podcast. Well, second to spacecraft fire safety, that is for sure. So that will be it. I won't prolong this much because it was a lengthy episode. Anyway, just one announcement. As mentioned before, I'm trying to make questions and answers, episodes, Q&As. They will air monthly at the end of the month. You can submit your questions either through emails or through the SpeakPipe add-on on the website. Please use them, ask questions about the podcast episodes, about fire science, about meaning of life, whatever you like, and I'll try to answer them as well as I can in the monthly Q&A episode. I guess there's going to be fun. I already have three or four really interesting questions. So the first one is looking promising. Please don't make me speak about meaningless stuff. Ask questions so I can answer them. So that's it for today. See you here next Wednesday. Bye. This was the Fire Science Show. Thank you for listening and see you soon.