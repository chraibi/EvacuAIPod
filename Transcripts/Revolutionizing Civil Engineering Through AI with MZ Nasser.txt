 Hello everybody, welcome to the Fire Science Show AI episode again. This time not about our chatbot friends that makes our lives in writing and coding much easier. Today we are talking about the real AI. One used to investigate complicated datasets with multiple variables, find hidden patterns and classify things in ways that we can cannot figure out on our own as humans. You may remember I had an episode about this already. It was episode 28 with Amzin Assar, who is one of the leaders of the AI revolution in civil engineering and in fire safety engineering as well. And today I have invited him again, almost perfectly two years after this previous episode, with a great occasion for this being his book being finally released. MZ has written a book about artificial intelligence for civil and environmental engineers. It's not a coding book that gives you snippets of code that you have to write on yourself and see. It's a book that will tell you why you need to learn AI and what you can get from that. So a very interesting addition to anyone's bookshelf. In this episode, we explore why explainable AI is a thing and why we need it, explainable AI is a thing and why we need it, what's causality and how you can figure out some really clever things by understanding how AI came to conclusions and how this can help us understand physics better. So if you're interested in AI, if you're interested in new technologies, how this is growing, developing and how we will be able to use this in near future. This episode is for you. Let's spin the intro and jump into it. Welcome to the Firesize Show. My name is Wojciech Wigrzy≈Ñski, and I will be your host. Fire Science Show is brought to you in collaboration with OFR Consultants, a multi-award winning independent consultancy dedicated to addressing fire safety challenges. OFR is the UK's leading fire risk consultancy. Its globally established team has developed a reputation for preeminent fire engineering expertise, with colleagues working across the world to help protect people, property, and planet. Internationally, its work ranges from Antarctic to Atacama Desert in Chile, to a number of projects across Africa. In 2023, OFR will grow its team and is keen to hear from industry professionals who want to collaborate on five safety features this year. Get in touch at ofrconsultants.com. And now, back to the world of AI with Amazin Assar. Hello, great to have you back in the show. Thank you very much for having me. Thank you. I'm very thankful you took my invite. Two years ago, we've talked about AI. Today, we're going to talk about AI, but I have a strange feeling AI is something else today. When we discussed it, it was a magical black box that can do things you don't understand. Today is this mysterious chat in your computer that answers your questions and makes up citations. That's what I think the general public thinks about AI nowadays, and both of those are incorrect. So first of all, how is this AI revolution happening in front of your eyes affecting your work as AI pioneer? I mean, thank you. You're too kind. I'm not really a pioneer. But I think when I see the AI stop going so fast, it's very scary at some point because you try a few algorithms and now you have something new. Someone else tries something else and the publications are extremely derived. I mean, if you look at Twitter, people just share their preprints now much more faster than what journals or conferences can do, and it's just amazing. I don't know where it's going to be in the next six months or a year from now. The growth is immense. I remember reading one of your review papers where you were already showing thousands of papers in engineering alone using some sort of AI, and I think it is safe to assume that the number will just go higher and it will go high exponentially because of how useful AI has become. But also, I would love to highlight your recent achievement, which is publishing a real book about this. Not that the previous papers were not good enough, but this one is a real book. It's called Machine Learning for Civil and Environmental Engineers, A Practical Approach to Data-Driven Analysis, Explainability and Cautiolity, published in Wiley. Congratulations on your book. And what I feel looking through the book is that it's really written with a user in mind. It seems you are very interested in actually having people use this. And this is not a book that teaches you how to code. It tells you why you should. Exactly. So to be honest, this idea started, I think, in 2021. Somebody from Wally reached out to me and we started from there. And I always wanted to write a book on AI. I just didn't think it was going to be this soon. And once I started the project, I wanted this to be something personal. I didn't want this to be like a traditional textbook that says, you know, this is step one, two, three, and four. I want it to be more like a conversation. So you would see a lot of footnotes everywhere, a lot of highlights because I'm trying to figure out, okay, if I read this as a student, what the questions would be, what would they have in mind, and maybe if I can address this directly, like in a footnote, then it becomes a little bit easier for them to see what I was trying to say or do, basically. We started with a draft, and I had a little bit of resistance from my editors because they didn't like the whole footnote approach, but I was able to convince them. It turned out to be nice. The goal from the book is really not to teach you how to code. The point from the book is not teach you how to use algorithms. The point from the book is to teach you what AI is, what machine learning is, how to think when you use an algorithm or a machine learning model, and how to can, if you look algorithm or a machine learning model, and how to can, if you look at the results, what do the results mean? There's a lot of emphasis on, as you mentioned, explainability, causality. There's a lot of emphasis on saying if this model gives you a good prediction, you just don't take it for granted. This is how you actually dissect it and figure out what to do. And hopefully it turns out to be like a very good textbook and service for everybody who is interested in this area. I think you've hit the bullseye with this approach, which I guess perhaps as an AI specialist, you could see this coming more than anyone else. I mean, the chat GPT revolution and stuff. But really, you know, writing a book today about how to code when there is a chat GPT revolution and stuff. But really, you know, writing a book today about how to code when there is a chat GPT that can code and tell you what it's doing alongside, it's not as attractive as it used to be to teach people how to code, but to teach people why they should and what are the outcomes they should expect and what should they aim for. Now coupled with capability of a layperson to code with the use of ChatGPT, this is such a powerful combination. So I think the book has just received an unexpected boost through AI itself that can help the reader to actually implement what is in the book. Implement what is in the book. Now, when we talked the last time and we were discussing how different models in AI are classified, I came to the conclusion that actually we should classify them by using them for finding results, for obtaining results. And we can use them for discovering stuff, discovering new things. for discovering stuff, discovering new things. One perhaps more fit for engineer, the other more fit for scientists. How do you view it two years later, observing the growth in this field? I think that using AI to predict things, it's not as impressive as it used to be. I think it's very intuitive that somebody would say, well, here's a problem, and they have used AI or, like, algorithm X, Y, and Z, and I can show that these algorithms can predict this phenomenon very easily. When I review paper like this, I think much more recently. I tend to be a little bit more maybe harsh because we know AI works, and we know it works very well to predict this stuff. So having an extra model that can tell me what's the compressive strength of concrete or what the fire would be is something that's good to have, but I don't think it's as noble as it used to be. I'm much more interested now in using AI to figuring out stuff that we did not know before, discovering new knowledge. For instance, if you think about experiments, we carry an experiment or a number of experiments we take the results and then we analyze them we have an equation the eye can do the same thing but however when it comes to ai it can analyze the parameters or space of features much more effectively and it can accommodate them much non-linearity and high dimensionality pretty easily and because of that we might be able to figure out new things that we didn't know before, or at least see things that we haven't seen before. And I think that's a little bit more exciting, because if you can discover something new, like a new stream of knowledge, you can go back and update equations, textbooks, information overall very easily. So nowadays, I also see that in journals, like simply applying a neural network to solve a simple problem. It's difficult to consider this as a novelty. It's even difficult to consider this as a useful case study because it's simply applicating the technology that we know that exists and that can work quite well. But applying this on meta-analysis of databases, for example, to discover new relations or new variables that are in the play, perhaps new dimensionless numbers. This could be very interesting to find a combination of parameters. Like for me, the most obvious is KROC, the capacity of heat, which defines so much in fire, and it's a combination of three variables for a material. It defines so, so much. Perhaps we can use AI to find new K-Roses in things we were not looking at. Did you try something like that? Did you have any success unraveling new ways of looking at data? Yeah, I mean, we're trying now a few ways. We have a few publications under review, so hopefully these will come up soon. One of the things that's very, very strong to get out is we talked about spawning, the spawning case. So this was a very interesting case. Spawning has been a big problem for many, many decades. A number of groups have tried, you know, and they are still trying to come up with different ways to measure spawning, previously spawning. Very famous professors and their groups tried that through theoretical analysis, derivations, statistical analysis, numerical simulations. And if you start to look collectively at what we have, you would see that if we go through the derivation approach, we have to establish very, very hard assumptions and hard idealizations that sometimes doesn't seem realistic to have because we can't really, for instance, control a lot of things and we have to assume them. And numerical analysis by default has limitations because a lot of the softwares we use are based on the theoretical derivations we have. Statistical analysis can be something interesting to go for, but to use high order or nonlinear statistical methods. We have to struggle a little bit with data transformations and all those things. So it just made a lot of sense to use AI because when we use AI, we don't have to worry that much on data distributions or on transformations or on the nonlinear relationships between parameters or theoretical derivations. It's basically saying, okay, we have now this furnace, and we're applying some tests, and we take some empirical data, and this is what we learn from data, except with AI, it can be a little bit more accurate. And if you think about the problem, as you mentioned earlier, this is really a two-way problem. For engineers, what we care about mostly is would this concrete spawn or not. For scientists, we would like to figure out how would this spawn and why and how can we prevent it? So to come up with a practical solution, we can just say with this AI model now calibrated spawning very accurately, which we show it can. We have a number of algorithms at very, very high accuracy across multiple of data points, thousands of data points. And we show it works. Now we're trying to figure out why does it happen? And if we know why does it happen through AI, what can we do to prevent it? Versus, you know, if you open a building code, it would say use BP fiber this much or use, you know, less water moisture content this much percentage. And it should be good to go. In reality, this doesn't seem to work as well, but this is the one thing that we know that can help us and innovate the threat of spalling. Actually, you chose a very nice example because I am following very closely your work in spelling here. And I remember, I think two years ago, there was a paper that was showing graphical heuristics for spalling, where you had a massive diagram of different variables, moisture, what kind of materials are in the concrete, what temperature and what's the growth of temperature. And by placing values on those, you could eventually reveal a probability at which the spalling may occur or may not, based on the results of a large amount of experiments. I think it was a few hundred, like 300-ish. Correct. Yeah, and now very recently you've published a paper on 1,000 tests that you've investigated in spalling. I wonder, like, how did your view evolve from that first graphical heuristics paper to the new one where you present new observations related to spalling and what you've learned along the way this is a very interesting case study but let's try to dig even deeper like how did you approach the first one and what did you change going to the second one yeah so this is interesting that we really had a very simple answer the The answer is, we just wanted to predict if a concrete mix would spoil or not. Yes or no? Yes or no. As simple as it is. And the approach we followed is, if we see, like if we do experiments and we have multiple different concrete mixes, we do the tests, we can see in the test it would spoil or not. Yes or no? So if we collect as many data as we could at that point in time i think we had two three hundred maybe two to two ninety something specimens maybe we can teach ai and you can come up with something very simple something that doesn't require coding that doesn't say python or r it's like a page that you can you know fill in connect the dots and gives you an answer so with my student arash did that and it was it was successful and then we said okay well now this was two years ago we continued the research and we were we were able to collect much more data points about a thousand something data points and this is where my other student Mo picked up the the project and to be honest with you when we tested the 300 specimen versus the 1,000 specimen, the nomograms did not change as much, which tells us that adding more data points is a little beneficial. But somehow the prediction of this phenomenon doesn't change as much if we added more data points, which in a way tells us that maybe to figure out the spawning mechanism, looking at the key features or the key parameters, we might be able to predict if spawning would take place or not. Now, as we all know, there's a big difference between predicting something, if it's going to happen or not, versus knowing if something will happen or not. Now, the knowing part is where the causality comes in. The prediction part is just an empirical analysis. It just happens to be carried out using AI versus regression, or versus, you know, just regression in this case. So this is what we did. I think the most interesting result was two things. One, we can do this with AI very easily and very accurately. That exceeds a lot of the theories we have so far. So if you look through literature, there are multiple theories that say if you focus on these parameters, you'd be able to predict or this or this. We use AI and the predictions from AI exceed all of them. I mean, most of them, if not all of the theories. The second portion is when adding more data did not seem to change AI's logic as much, which is extremely important because one of the things we always, I mean, tackle with reviewers were, what if you add more data points? What if you add more data points? Well, at some point in time, adding more data is not going to really solve the problem as much because you're just providing examples. And it's going to be up to the method that you use to figure out a way to make use of this data. If you use regression, you'll be always confined with regression principles. For instance, linearity, R squared is R squared, certain things we can't really go away from. If we use a nonlinear method, you can be applying nonlinear method. However, you'll still be confined with the assumptions used to create this method. So what we're trying to say to do is let's minimize any assumptions regarding to this method as much as we can. And maybe we can find something new and let's start with prediction first, if we can predict and then worry about the mechanisms. And now we're worrying about the mechanism because we need to figure out what are the mechanisms at least from an AI perspective that can if we know, maybe we can go back to the theory and we say well this theory has a very good benchmark or has a very good foundation. However, if we now add the data we got or the information we got from AI basically on data-driven analysis, this is how we can make it better or this is how we can fill in the gaps that the theory did not really fill. Because at the end of the day, as we all know, all of these theories were done based on specific type of mixes, specific type of tests, specific number of specimens. Nobody has in a theory would be analyzed a thousand specimens or 500 specimens. Most of them were very small. Especially that we are talking about 40-something variables in there. So I actually find it quite astounding that AI could literally make sense out of such a huge data sample and then give you predictions or outcomes. You have used it to explore the results of this huge database, asking questions like how does compressive strength affect that? How much times we've seen spalling i am really astounded in how it can make sense with such a scatter of variables such a you know diverse amount of things that are going into and provide meaningful outcomes i also really like how it's used you know there's there is this flag, needs future research. I love that. Actually, tell me more about this need future research tag for some of the variables. Whatever we did with a data-driven analysis, we have to use domain knowledge. So we have to apply what we know about the problem. The matter was we just didn't put numbers. So we were thinking of when we have some exogenous factors, these are in a fire heating rate. Because without fire and heating rate, we don't really have spine. We also have some endogenous factors. For instance, concrete mix moisture content, existence of BB fibers, and so on. So if we start to apply our domain knowledge on the data we have, then our data-driven analysis becomes a little bit in a higher level. It's no wonder just numbers. Now, we have some physics in it. Now, if we add a third layer, if we establish now the relationships that we at least know, although they may not be 100% complete or full, but some level of relationships, now we're going to grow from domain vision into including physics. of relationships, now we're going to grow from domain vision into including physics. Now if we have this physics and then we add some relationships from statistical analysis, let's say on causal inference, we grow into a causal analysis. And with each layer, we discover some new stuff. Now the very basic layer is just predict. For instance, if you think about kids or pets, if you open the fridge, they would expect a treat. This is association. This is what prediction is in medical analysis. You do something multiple times, you get to know what would happen once you do it again. However, once you start now to link, well, now I'm going to open the fridge, but I'm going to take water. They won't expect a treat because now you have water. You don't hope that something sweet or something that they would like. So you start to add a little bit more layers under the features. And the more layers of knowledge you add to the features, the better it becomes overall for analysis because now the algorithm starts to link things much more cooperatively together. If we can jump back again to the beginner's mode, last time we've talked, I've asked you a difficult question, what's the sample size that you can start working with? And I guess the question is, you know, as important today as it has been two years ago. Back then, the answer was 25-ish for regression models, 100-ish for classification models. Has this changed over time? Has this evolved? Because now you say that going from 300 to 1,000 did not necessarily change the qualitative prediction, though perhaps if there was an outlier in that, it could, we won't know that for sure. That's a good question. I think that the research for the smallest number of data points is still going on, but I think it's just what we mentioned last time. It's applicable to some point, 25 to 30 observations per variable seems to be the bare minimum that you would like to at least run a machine learning model that one can confidently say, this model now, we have some confidence in it. The more data points we have, of course, the more the confidence or the reliability becomes. However, I would like also to touch on one point on this aspect, and I thank you for bringing it. I think one of the things that we tend to miss a little bit is our problems in engineering or, let's say, in fire or spawning, the number of parameters is really confined. For instance, if you think about concrete mixes, we don't really have mixes that have very, very different proportions of materials than the other mixes, because when we build the structures, we have to have the mix that can, you know, still have carry strength. It still has the other parameters in there. So our space of parameters is not really that varied that much. And because it doesn't vary as much, we don't, we may not need as many data points as we do. However, if we have a space parameter that varies across all the parameters, let's say width and length or the size of data points, then adding more data points would most likely show us some difference in AI prediction would affect it. If you look at AIs in medical research, for instance, when the papers analyze, I don't know, 50,000 genes or 100,000 genes of 100,000 people, the number of parameters is so massive because their problem is massive. And hence, any change in the parameter and the data points were significantly affecting their problem. In our case, we have a fixed number of parameters and it doesn't vary as much just because we have to have them to make the concrete, for instance, work. I will challenge you to extend because I think there are much more parameters out there than we think there are. And, you know, we only focus on the known ones. Like, for example, if we talk concrete, I can bring up the question of 3D printed concrete, for example. And here, OK, we can talk about the megapascals of the strength and stuff like that. But how about the time delay between the next layer was caused, the moisture of the air when it was done? Was it windy or not? Was it sunny or not, you know? And you would not normally record these properties of the surrounding world until you understand they can make a difference. And now we start to understand that because there are papers on every single of the things I've mentioned. And we know that. The same in fire experiments. Let's assume we investigate mass timber experiments. But how many of them would tell you if it was sunny or not the day they carried out the experiment? Or how often you would consider this being a variable? So I think there's also a trap, you know, of the fact that we recall the things we know that make a difference, but it's not a complete list. But this also brings to the ability to do sensitivity analysis for different parameters, like you have done for the spalling. And if you see there's a parameter on which the variability is great, or if there's like an unusual distribution, like it can be a peak at the end, it can be even result over the whole distribution, you know, it can show you where to dig further and where to seek more answers. And then perhaps this machine-learned, fueled approach can help you dive deeper. Correct, 100%. I mean, the issue with the chromatic parameters is mainly domain knowledge. I mean, we just record, for instance, the strengths and, you know, when the collapse happens or when failure happens. We don't record other things, like maybe weather conditions as much. The internal sizing of the furnace, the type of furnace, or the gas used in the environment. All these things are parameters that we have to think about. And when we think about this, of course, the more we document, the better our models become, the better. But at the same end, at the same point, what I'm going to say, I'm not trying to contradict you. I'm just trying to say engineers seem to be a little practical. And because of this practicality, we have to say, okay, we have to establish now this parameter does not influence. But we don't know. We don't know how much it does influence in the first place. And because we just have this hard assumption that it doesn't involve anything, so it may hinder our analysis a little bit. And because it may hinder it, we can't really figure out why. But the good news is, with the parameters we have so far, and I'm talking only on SPAR, with the parameters we have so far, we showed very good accuracy and confidence in predicting spot so perhaps adding more parameters may increase our accuracy a little bit but the accuracy we have so far is is almost 90 percent so if you think about it out of 10 samples you can predict like very easily and predicting 10 out of 10 may seem would would be great but i don't know if we can confidently say so. And this is where maybe we have to start to think about other ways of analyzing our model. But it's a very important point. We are talking about a phenomenon for which we don't have one grand model. It's not that we can predict it with a bigger accuracy with any other known tool. I'm planning an episode on Spalling overall, so that's going to be an interesting discussion after this one, for sure. Now going back to having engineers or scientists use AI, one thing that is really interesting to me is this coding-free versus coding-based approach to machine learning. If you could tell me what do you mean by coding-free? I thought it's always coding. No, this is a good point. This really started from thinking about what to do with AI. In civil engineering, for instance, a lot of it, many, many universities, we don't have coding courses. We may have a course in the second year or first year that say this is a programming course, and students usually take it. They're usually freshmen or sophomores, but we don't have follow-up courses. So when I try to do my research and hire students that are familiar with AI, I usually tend to struggle because I have students that are very, very good engineers, but they're not really good in coding. And if you take them, you're going to have to wait until they learn coding. So usually they have the latest start. So once we started to look at this problem, we said, okay, well, we don't really have to use AI with coding all the time. Now we have softwares that have AI algorithms built in them, and they have a very nice user interface. And all that you have to do is upload the data and pick, I want to use, for instance, algorithm X or algorithm Y or algorithm C. The software runs the algorithm for you, gives you the output. So you're using AI, you don't have to code for it, and it's your job now to analyze data and figure out what to do next. So this opened up the door for learning AI through coding or through coding-free software. My preferences for maybe engineers who are well-established, senior engineers, or they have left school, is to learn the principles of AI, the big ideas behind AI, and then use coding-free software to use AI. For younger generations, learning coding is something beneficial because it's like a new language. However, as we all know with chat GPT, code interpreter with data analytics, the reliance on coding, at least for us civil engineers, is more likely to be less and less. Because if you can have a tool that you can say, use XGBoost to analyze this data without having to code it yourself that be substantial because you don't have to waste time and resources learning to code plus using all this coding stuff and you pick it up while using that in some way anyways i'm also a huge fan and i recommend it to my students and i have colleagues in my office who work like that. They used to learn how to do Python and stuff and they would invest time but with this new approach it's just so much easier and so much accessible. Well, the thing out there is still that you can use non-coding based softwares and that's also a brilliant thing. So, in the same way how we use CFD software today without having to program Navier-Seux on our computers anymore because there exists a package that does it for you. I also know an important thing for you was the explainability in AI. And we've briefly discussed this in the previous episode. Maybe you can tell me again a little more about what do you mean by explainable AI and what's the purpose of having that? So the goal from explainability when it first started was to say that I have a model and this model uses this data and it comes with a prediction and I can use an explainability tool slash tools to figure out how the model was able to come up with this prediction and the intuition was if i know how the model was able to come up with the prediction maybe i can uncover the missing relationships that they don't really have now or the physical relationships that they don't have so this was a promise and i think the promises continues to be this way however the explainability tools we have so far, for instance, Lime, Chab, all these different types of tools, what they do is they show you how the model was able to come up with the prediction using your data set. So it uses your data set to show you how the model arrived at the prediction. It doesn't show you why the model arrived at the prediction. For instance, you have five data points and the model predicts, let's say, a number 50. It would say from these five data points, it uses data point one, 10%, 20%, 30%, so now we're 60%, 20% for the last two points. And these come up with a 50 value for the prediction. But knowing this doesn't really tell me anything about the physics of the data or the physics of the problem. It just explains numbers with numbers. Now, this could be beneficial, for instance, because I can go back to the most important features used to come up with a prediction, and maybe there is a physical meaning behind it. However, there is no guarantee that there is actually a physical meaning behind it, and hence explainability continues to be something important. But for us, for dealing with our problems, it may not carry the promise that it initially had. Because we still don't know the physics or the missing relationships. We still don't know the physics behind the problem. And most of these explainability methods, unfortunately, they still assume the relationship between the features to be some form of a linear relationship. And we know that this is a very hard assumption to have because relationships between parameters and engineering problems are likely to be non-linear than being linear. Can you use this concept to verify whether the prediction is happening in physical constraints? Like, you know, a fire from a chemical reaction cannot be 10,000 degrees Kelvin, right? So there is a hard limit to that. And many of our things would have hard limits to that that just come from the real-world limitations. Is it something that can be used to check if the prediction happened within the physics realm? Exactly. So this is one very good example of physics. You have a prediction, and when you analyze it through explainability, you can at least have a good feeling that the algorithm or the model did not use something out of physics or something tremendously very far away from what we expect. However, the problem is we're still using domain judgments to answer this question, and we still don't know the relationships between the features. So it's a way to check, but I wouldn't say that checking this would imply that the algorithm actually understands the problem. You know, the goal of these algorithms outside of scientific curiosity is to have them do something. And you would expect to answer questions that come outside of your data set. You're not going to ask endless questions about your data set, about your spalling mixtures. In real engineering, you will have this one mixture you don't have data for, and you want to figure out to what extent this is going to spall or not. So understanding that the model is not only giving you a prediction, but its reasoning is within the limits of the physics, perhaps gives you a little more trust towards the prediction itself. Because if I knew that the model predicts it perfectly, it just assumes the concrete turns into plasma in the meantime, I'm not sure if that's a prediction I would like, even if I know it's 90% on the data set I used to train. 100%, I agree. And the second thing that comes together with explainability, the interpretability, what about that? So, explainability and interpretability, for us civil engineers, fire engineers, more or less, they're the same thing. For computer scientists, they're much more different. They have different philosophical look as well. So, for instance, one group could assume explainable AI as if you take an algorithm, and the algorithm can tell you how the prediction arrived at. Interpretability, you take the algorithm and it tells you how, not the prediction, but what's the mechanism within the algorithm that arrived at this prediction. So for us, the technicality might not be something that's extremely important for us. Because for us, we just want to know why, for instance, or how come the algorithm came up with this number. But for people who create algorithms, knowing the mechanism itself also can make a big difference. Because, for instance, a neural network doesn't work as well as another algorithm X or Y or Z. So if you can constrain the mechanism, you'll be able to know why. On the other hand, if you know the relation, if you know how the value was arrived at from the data, you'll also know how. And another problem from your book, casual discovery Discovery and Casual Inference, how you define that? Okay, so this is something that's very exciting for me. Causal Discovery is when I know, if you take, let's say we have five parameters, and you draw a line from parameter one to two, for us it's a parameter one causes parameter two, and two causes three, and three can be the predictor. Machine learning now doesn't give you this. It just gives you values and a linear relationship between the parameters. Cosmology tries to figure out what's the map, what's the DNA of this problem between these parameters. So for instance, if I know from cosology that parameter one causes two and two causes three and three causes the prediction, then I might as well instead of having one, two, and three on parallel rows to each other, because I only need one, because I only need the one that actually predicts the phenomena. And if I know the relationship between the parameters, then I can easily come up with a hypothesis. I would say, okay, now instead of having five parameters that gives me a prediction, I know that two of them are outside the parameters, and I don't need them that much. But these two cause the other three parameters, and now I can confidently use the three parameters to predict something very easily because I have the map. So it is kind of like a forced neural network from the start. So you know what's going to happen and you're plumping some things together because they cause each other, right? Exactly. But the map happens at the output of the analysis. It's the map. Okay, so it's about finding what... Okay, which one... Okay, that's reverse. Yes. So instead of coming up with a prediction with a value, you come up with a map. And for the same data, you could have like multiple maps because multiple parameters could initially interact, right? Now, because multiple parameters could interact and you could end up with multiple maps, it becomes now which one of these maps is more physically possible. Fantastic. And from there, you come up with a hypothesis, you'll go back and you test, and then you come up with a new theory, for instance, that says, okay, well now I have this map. Now the other interesting thing is if you have the map, all what you have to do now is to change one parameter on this map to know if you're going to have a prediction or not. But the difference between changing this map and changing a model, my map has a lot of physics, has a lot of domain knowledge. Machine learning is based on data. And machine learning gives you explainability after the analysis, not before the analysis. So you can't really control machine learning. You can control the causality because at least before doing the analysis, you have a good way of inferring what would happen to this man. So this investigating causality looks like really a way to do real science with this. By science, I mean on discovering the fundamental principles behind the phenomenon, because this allows you to understand what caused the final outcome. And then, of course, knowing the course, you can change one of the steps and see if the prediction matches new reality or not. And what you said about testing, if parameters are within physical limits, that's what my friend Michal Malendowski did when he was solving the adiabatic surface temperature equation, because it was in the fourth power and everyone was solving that as an iterative, because it was in the fourth power and everyone was solving that as an iterative way because it's kind of annoying. It has multiple roots. And Michal just solved for all of the roots and just, he was speaking like, okay, this one is unphysical because it has a negative energy. This one has negative temperature, not really possible. And one by one eliminating which actually makes sense in the world of physics, in the physical realm, was able to figure out, okay, wow, this one route is really making sense, and it simply works. So, do you have an example where this was used in practice, or is something very new? Yes, so the first time I heard about consolidative was from a computer scientist paper or so, and then there is a very famous quote by Da Vinci, and he says, I think, something like, there is no result in nature without the cause. Understand the cause, and there is no need for the experiment. And it was something interesting, because if you know how things happen and why, maybe we don't have to spend as many resources on experiments as maybe we can do a less number of experiments so there are a big causal influences is a big the very big area in social sciences plus science there's a lot of professors who do research there a lot of the causality stuff comes in medical for instance if you have a random trial and you have a drug or a vaccine for instance some experiments can be inefficace. You can give people a drug and it might be harmful for them. So you have to use causal inference to figure out how to analyze the data and maybe discover some maps and then maybe figure out a way to treat other patients. Also, it could be very expensive. You can't have an experiment on 10 million people. It's the same thing for our stuff. You can't have an experiment on 10 million people. It's the same thing for our stuff. We can't test 100 beams in a furnace because it's extremely expensive. So those limitations will bring causality. And much of the research is in social science. How can you control income? How can you infer education for students? What to do in, say, low-income neighborhoods? And the policies, a lot of these things don't really have an experiment for them, and we have to rely on causality to come up with. In a similar way, you could use the same approach to investigate fire statistics on extremely large datasets. Fantastic. And as we're heading to the end of the interview, last time when we talked, my big takeaway from the discussion was that if you want to apply AI to a very general problem, you're not going to have a success because it's not like the amount of data and variables and everything will simply prevent you from obtaining a very general solution. But if you are capable of narrowing down your issue and then finding an algorithm suitable for that issue, AI generally tends to do a great job. Now, I wonder if you have some examples of perhaps failed or unsuccessful applications of AI so we can understand. You know, everyone is talking about the success is very rarely that someone publishes a failed attempt. So perhaps you can give me, you know, behind the curtain pick on what didn't work. So people listening can avoid like, you know, traps or the simple mistakes that go to black holes. Yes, I agree. I agree with you that we don't have many publications that show the negative sides of AI. And I have, I mean, my student, Mo, he has a very decent paper. Hopefully, it would be accepted where we actually show that if you have multiple algorithms and you take one leading algorithm that everybody's talking about and you apply it to the spotting problem, this algorithm will give you very, very good predictions with physically impossible features. So although you have all the features that you want, and the algorithm can give you very high predictions, it will still fail to give you something that we can all agree on that causes this phenomenon. However, other algorithms, and this is deep learning, by the way. Everybody's so good at deep learning. If you take very simple algorithms or algorithms that are a little bit more modern, they can do a much better job. So when it comes to a big item from AI is never rely on one algorithm, never rely on one model, never rely on one data set. Do your best to use this ability. Do your utmost best to use some form of causality and make sure you understand the principles very, very well. Because you don't want to just come up with a number, and this number, although it's correct, it can come up from a physically impossible method or way that you can't really figure out. And if one number can come up like this, there is a potential for the same algorithm, same mechanism to give you other numbers. And when it comes to data points, when we use, we've tried a few multiple data sets and what we found is if you use 15 parameters or 45 parameters or five parameters, there is a very good chance that the same algorithm will give you more or less the same accuracy, which makes a lot of sense because in medicine, they have 50,000 parameters and their models seem to work. So it's going to always come down to education. You have to really understand the principles. Don't be afraid to use coding. It would be maybe a little bit easier to use non-coding methods, but the principles will always be with you. I'm going to end with this point because I think it's important if you allow me one minute. Of course, when we teach finite element in courses, we usually teach 1D and 2D elements. We don't really teach 3D elements. But when we graduate, we use softwares. Most of them have 3D elements. And we learn 3D elements from the software manual, not from the course. Same thing with AI. We can learn the principles in school. And then once we're out there in the field, we can always relate back to the principles because these will never change. Fantastic. Thank you so much. And I will link to the book in the show notes. You have a fantastic blog about AI and all the resources that you are producing. So anyone interested should go there. Any other specific resources that I should link? No, I think the book would be fun. Thank you for your interviews. Keep up the great fire science show. I always listen to it. Really? Thank you so much. I'm very happy. You should have a YouTube channel soon. Perhaps one day. I'm too ugly for YouTube. That would dramatically decrease the amount of views. It would be great. It would be great. It would be great. And that's it. Thank you for listening. The most shocking finding of this episode for me is that I am unable to spell the word causality. Causality. Horrible. I've heard that Germans are unable to say squirrel, and causality is my squirrel. I am very sorry for butchering this so many times in the episode and that you had to witness that but hopefully it was worth it i think the knowledge brought by mz is just amazing and the best thing is he's leading by example the point is that you can do stuff like this as well we didn't even explore that much how he's exploring all test results and big databases with the use of AI methods. I think it's also very intriguing. If you jump into the previous episode, you'll learn why perhaps you should not take all of the data available and why results from 50 years ago may not be that representative for the today's situation, but overall, it is a brilliant way to study the history of fire safety engineering. And you know what? Many times in long forgotten experiments, there still is knowledge to be found. And you as someone who's running science, who's doing projects, who's doing research, who's designing stuff, you have no idea, I have no idea what is in the work I do or what we do. There are always hidden things that we are unaware of and there has to come someone who will show and point it to us when it becomes kind of obvious. And this is how the best breakthroughs in science happen. So thank you very much for listening. I hope this episode was interesting and inspiring for you. There is a book to be read. And for the podcast news, it just has passed 100,000 individual episode downloads. That is a big number. Thank you very much for listening to the Fire Science Show and for being here with me. It means a lot for me to have an audience, to know that on the other side of the microphone there is someone listening and enjoying this. I appreciate you a lot. And yeah, let's go up to a million. That's the next skill. Thanks for being here with me today. And yeah, it was the billion. See you here again next Wednesday. Cheers. Bye. This was the Fire Science Show. Thank you for listening and see you soon.