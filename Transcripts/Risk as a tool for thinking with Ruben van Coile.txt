 Hello everybody, welcome to the Fireside Show. Today we are going to talk about risk once again in the podcast. Risk was a topic that we have touched a little bit. In episode 23 I've hosted Jaime Cadena Gomez and David Lange who were talking about a maximum allowable damage approach to risk and how can that be used in the design of the buildings, what's the baseline level of risk in buildings, how using risk as a framework can help you build a better building and understand your building much better. It was a very nice episode and I enjoyed it a lot. And then in episode 45, I had Ruben Van Coyle and Danny Hopkins talking about the foundations of fire safety and how risk can be such a concept that is fundamental to fire safety. And I truly believe it is fundamental to fire safety. So I thought it could be nice to dig more into that, actually, to make it a little more approachable, because we've been talking with these experts on risk about their sophisticated methodologies or use of the risk at the really, really highest level to unravel the fundamental fire safety of our buildings. But so far, we haven't really covered risk on its own in the show. So I really wanted to fill that gap because I know it is an important concept. It is a fundamental concept to all of us, but it's not a very approachable one. It's a little difficult. It's not very intuitive. So I would really love to talk about the risk as a concept on its own. And for that, I've reached out to Ruben Van Coyle, one skin, and he has agreed to start the episode again. A nice welcome to Dr. Ruben Van Ccoil from Ghandi University to the show. And that's exactly what we will be talking about today. Risk as a concept, risk as a method to understand the fire safety of your building, risk as a fundamental benchmark of the safety in your building, and risk as a tool to take engineering decisions. A very nice engineering tool. I hope that if you have never used risk as a concept, well, actually, you most likely did. If you're a fire engineer, I'm 100% sure each of us has at some point used risk as a concept to develop fire safety strategy for a building. If you know it or not, you did. So now I guess you can use it more as a tool as it should be used. And I hope this episode is something that helps you work with this concept a little more. And I hope you will be more open to using risk as a tool in personal engineering. So a very useful episode. It's not a guide on how to RISC. It's not a course on how to use RISC, but it covers a lot about what RISC is and how can be used as an engineering tool. So yeah, let's spin the intro and jump into the episodes. Welcome to the Firesize Show. My name is Wojciech Wigrzy≈Ñski and I will be your host. Hello everybody. Welcome to the FireSense show. I'm joined today here by Dr. Ruben Van Coyle from Ghent University. Hey, Ruben. Great to have you back in the podcast. I'm very safe. Thank you very much for the invitation. Oh, man, I'm so happy you took this invitation and took this subject. And I'm stressed because it's hard stuff to talk about simple things in fire. I've asked you to discuss some concepts about risk in fire and risk engineering in general, because I believe risk engineering is fundamentally important for the future of fire science and fire engineering. And yet I find it is difficult to approach. And I know a lot of people, it's not intuitive. They don't really understand what is being said when you talk in risk. I think we may have a communication problem in here. Like how do we engineers communicate some aspects of risk and how people perceive them? And I would love to talk to you about some fundamental concepts in this. So I'll just drop a bomb on you. Like, why not? Ruben, what's risk? Okay. I wouldn't say definition. As in, be careful when talking. I mean, I'm not going to make an encyclopedia or something now. But my definition about risk is very much engineering-based, I would say. So probabilities, consequences, and say a combination of probabilities and consequences. And I like to leave it there because many people go a step further and then immediately say about R is a multiplication, and then if the difference we're already talking about, and put that event tree, for example, different scenarios, each with their probability and their consequence, and say, are you going to multiply probabilities and consequences? And then you take the sum of all of that. But you're losing information by doing that. So to return your question, what is risk? A combination of probabilities and consequences. So what you actually, if you understand risk, then you understand how, in a fire situation, your building is going to perform in fire both probabilities, likelihoods of different performances, and consequences, as in what does it mean for people's lives, property, and so on. I like how you put it. I knew it was a good idea to invite you. In some school of engineering that I found, we also talked about the perception of risk as one of the elements of risk itself. one of the elements of risk itself. I guess it's maybe more towards the risk acceptance, that risk perceived as unacceptable, even if the mathematical formula would give you something that's okay, it could be perceived as not acceptable. So we were taught that risk perception is an inherent aspect of fire risk on its own. Now I'm looking, I have my eyes on ISO 16732, fire safety engineering, fire risk assessment standard with the vocabulary there. I hate encyclopedias, but actually for fire risk, they say combination of probability of a fire and then quantified measure of its consequence. And that's so close to your definition so that's really at least again for me that's really because we're talking about engineering right so this is of standard as well it's about engineering so risk perception very interesting probably you could say it's it's very important but from an engineering perspective i would say let's be careful and not immediately jump into that. I mean, people like to refer to all these aspects of risk perception. They also like to refer to concepts of behavioral economics and so on, about how people value very low probability events or also how they value consequences. consequences. But to me, this is more like trying to explain how people behave instead of providing an engineering tool, which then can be used to guide decisions as an input for the decision. And if then in the end you say, well, despite the input we gave quite, let's say, objective, as objective as possible, right, an engineering input, despite all of this, other human factors come in. I mean, human factors in the sense of subjective factors, okay, that engineering input. Despite all of this, other human factors come in. I mean, human factors in the sense of subjective factors. Okay, that's all good and fine. And maybe we need risk perception to sometimes explain stuff. But as inputs, I prefer to stay away from that. Yeah, that's very nice. Do you think this approach to risk as an engineering tool must be kept like that? So it is useful in engineering without this, how to say it even without how people perceive it i mean it to be objective it is to be objective you cannot put another metric on top of that because i mean it says this but i don't like it anyway right well that last point is also very interesting when you you say, should you keep it simple or basic in engineering sense, I would say yes, definitely. And it relates to what you said at the end. What you want actually is transparency. So to me, and probably I'm very biased, but to me, in the end, okay, probabilities and consequences, I can understand. But I can understand that at least you tell me that there is a likelihood of a certain event, can be fire-related, but can just as well be the weather, and there are different consequence magnitudes, and okay, I can grasp that, and I can make my own decision if necessary. But as soon as you already, as an engineer or somebody who quantifies things, starts to manipulate, this may be a negative term, but okay, to conversions or calculations with these numbers. Say, I'm going to take into account a factor for risk aversion or for the consequences too high, I'm going to multiply it with or take a power. You're making things much less transparent. So I very much like the transparency of just probabilities and consequences. And then we know what we can talk about. Everybody can agree on the values. We can disagree on how they were calculated, maybe. That's something else. But we don't have to talk about factors which hide things. Do you think we should, in that case, communicate risk in this dry way as well? Like, this is a number, it's a measure, nothing else. It doesn't have feelings, it doesn't have subjective understanding. I mean, like a temperature, ignition temperature is this, the temperature is lower, it does not ignite. If it's higher, there's a good chance it does ignite. And in the same way, the risk is this, so it's below our limit, whatever limit we've set. This decision should be formulated based on this value, and other decisions should be formulated on that value. Because it's very dry, you know, but maybe it should be. Maybe if it's an engineering tool, if it's a measure, I guess it should be. So the question is, do I think it should be communicated as objective as possible? And really, the answer is yes, definitely. The old questions about putting in values goes beyond what you should do when you're evaluating a design anyway. I mean, in the stage of evaluating the risk of a design. But how it then should be communicated, that's something else. I mean, the content gives, at the best knowledge you have, the likelihoods, the consequences, draw this picture of this performance of the building. People say, oh, risk is something different. No, risk is the performance of the building. That's what it is. You can't tell me anything else than, okay, I have a performance for a design fair and so on. Okay, so you have one little point in your entire space which defines probabilities and consequences. And you have mapped one or two or 20. And you're making yourself a picture of the performance of the building and the total performance of the building, the full picture, this is the risk profile or risk performance of the building. So should that be communicated dryly? Yes. How do you do that? Well, because there are many dimensions, it becomes, okay, that's something else. Yeah, yeah So you already started going into the communication space and drawing the graphs or putting points somewhere in a space. Like every scenario has its individual probability, individual consequences, I guess. You map them in some way, whether you multiply, whether you do some other mathematical operation to calculate that. It's the method, I guess. Mostly we multiply them, but I guess other ways could be formed. Then you end up with a scatter of the points on your matrix. Like you had one axis with probability, the other axis with consequences. That's the usual way how we would present risk in a two-dimensional manner. I guess now the difficult choice is where to draw the lines, like which point on this matrix is K, which point on this matrix is not OK. And I know from the talk we did with Danny Hopkins, we were talking a lot about this de minimis level. We were talking a lot about ALARP region in the graph. We were talking a lot about intolerable risk. And I guess it's very connected to this matrix and how we can use that presentation to understand the further choices. So let's try to define these regions on the matrix. Maybe let's start with the de minimis region, which I assume would be the lowest risk, right? Okay. Well, that's very fine. We have to maybe map that or introduce it a little bit. Because in your question, you said this multiplication, but actually, when you're referring to 2D visualization, like you said, with probabilities and consequences, there is no multiplication involved yet, right? There would only be this multiplication of probabilities of consequences when people want to end up with a single number. Yeah, you're right. Absolutely. So, at that point, you're just putting your, and we're talking about scenarios because this is the easy way to talk and think, but okay, of course, every scenario can be subdivided in further scenarios and so on. So actually, there are just a huge number of possible situations, right? Infinite. But that's one. You have your scenarios, and you can map them probabilities, consequences. First thing to say there is that consequences dimensions can be very different. So you have consequences on people's life lost, consequence in value lost, consequence in environmental damage. So this is very much multidimensional. What we generally do, if we do it at all, is keep it 2D. We have one vertical axis probability, horizontal axis consequence, and then what you are referring to, if you're talking about life safety, for example, an FM diagram, so frequency vertical axis, the number of lives lost or at risk on the horizontal axis. An important thing to say, and maybe I will have to refer my students to talk because every year on the exam there are mistakes on this is that on the vertical axis so this probabilities is a probability of exceedance so the curves they only go down if you go on the left hand side vertical axis you start there at the point the curve only goes down because it's the probability of exceedance. It's the probability of having one fatality or more. And then the next step, the probability of two fatalities or more, which necessarily is lower than having one fatality or more, right? So, okay. We have this graph. Maybe a bit difficult for listeners to see. It's a challenging task to do it in a voice here, but also gives you a completely different dimension understanding it. So, I'm very happy to do it in a voice share but also gives you a completely different dimension understanding it so i'm very happy to do that yeah yeah like this the thing i just highlighted this probability of exceedance is i always i'd say it as well when we have a lecture on this but somehow it gets lost maybe when it's not visual it will get it will get lost less. Either way, so in this space, we draw a curve, set of lines. Again, we can discuss how do you then do that, but a set of a line with probability of exceedance, consequence, and this then defines the risk profile of the building, which then can be compared indeed against different set curves. And one of those curves is what I like to call a de minimis curve. Not everybody agrees on terminology. Not everybody agrees. Even if they use the de minimis wording, they might mean something else. So this is all very tricky. What's very important though is that you realize what it actually means. And I am very clear about this it is a line which indicates at which point it doesn't make sense to invest in investigating further so it's like saying your risk profile is here it is very low basically this is an economic justification, basically any effort you now put in trying to find design changes or safety measures or anything which would reduce this risk will cost you your time and effort so much relative to the way the risk is that we say up front, you know what, this is fine. You don't need to do this anymore. But importantly, if you would know that a certain measure should be done, it's cost-efficient to be completed. If you know a measure should be done, then you still have to do it. I mean, it's not because, and this is one point where there is a bit of disagreement sometimes. People say, oh, no, once you're there, you're fine. You don't have to do anything. once you're there, you're fine, you don't have to do anything. No, it's not the definition that you don't have to do anything. You don't have to investigate because your investigation also costs time and money. So it's a group of probabilities and consequences, which in essence give you such a low value of risk that it's pointless to even investigate them. Because most likely, if you investigated, you would come up with it. It's safe. You don't have to do anything. It would be such a low, can I say low risk? Yes. So we talked about immediately about the lowest curve. A higher boundary limit would be tolerability limit, which we're going to talk about later and maybe a bit more detail. But if the design is not tolerable, big problem, we have to do something. Now, the fact that you are talking about the minimus means that you are already below this so that and when you're below the tolerability limit you're saying ah okay i can live with this design and since it's a risk profile if this has to be if doing anything to improve it costs too much is not reasonable then we can stick with the current design but if there is something we know we can do, we have to do it. And above the de minimis limit, you have to investigate. Below the de minimis limit, you don't have to investigate, because it's so low that you indeed already say, like, look, probably, yeah. And you can then define a fourth boundary, but I don't see the point, really. A lower one where you say, look, below this, even lower level, it's really negligible, but why would something really be negligible? Maybe you have to increase the risk. Well, yeah, and then because then you have papers or people discussing, ah, you talk about risk to life, risk to life is never negligible. Yeah, I mean, all fine. And I don't think we need to have that discussion. I mean, it is a discussion without content, really, because if you say it's not negligible, but you still say it's economically, you shouldn't investigate anyway, the conclusion is the same. What you said about we shouldn't, we should invest in safety anyway. Like if I'm sitting in one building and the fire is another building there is no point for them to invest in my safety anymore because i'm just not affected by the fire i even sometimes take it further if i investigate i don't know a shopping mall and let's say i i have designed a perfect smoke control system that maintains my smoke layer well above the occupants' heads. I achieved steady-state solution within my investigation. So with the time it does not change, I maintain this balance. There is never smoke on my evacuation routes. It's designed for a certain fairly high size of the fire in the building. Then there is no point to improve this system anymore. I've reached all my perfect goals of a smoke control system in this building. And if I now doubled the cubic capacity of the system, the exhaust rate, it would not mean the people in the building are more safe. You cannot double escape the fire. I mean, they are already in a very unfortunate, even having to be evacuated from the building are more safe like you cannot double escape the fire i mean they are already in a very unfortunate even having to be evacuated from the building with all the risks or all the challenges related to being evacuated and everything that can happen about that but my further investments do not improve anything towards the threat they are escaping from, which is the smoke. And actually, from my professional experience, I know that if I increase this, I would most likely worsen the situation because of the complexities in the air supply that would follow increasing the exhaust rate. But in the end, I've ended up with a system. There is absolutely no point in improving that unless we start talking about the design fire which has a probability of fires maybe i've designed it for a very probable fire but maybe i should have designed it for very very very improbable fire but still something that has a probability to it but that that's another uh let's let's come back to that in a second maybe we should talk about tolerability now if if we reach this point. Yes. Making a distinction what you just said. So with the information you just gave, possibly you're saying the risk profile is the minimus and you don't need to investigate anything. Possibly you're in an alarm region, right? In which case you're saying that, well, I already know that it will not be cost-effective to reduce. So, and just to make sure we are not on a sidetrack for some listeners, when I say ALARP, we'll return to that after talking about tolerability, but I'm not referring to specific legislation. I mean, I like to think in concepts. So that's also what I hope we get from today's talk, more concepts, and then you can disagree about specific words and definitions. So tolerability. So again, we are in this 2D plot. You can also make it multidimensional, if this is something you like, but nobody does that. So we start 2D, frequency of exceedance, vertical axis, horizontal axis, number of lives lost, for example. Your risk profile of your building goes there as a curve, which is decreasing. And you have the minimum limit. And then another limit, which is a tolerability limit. If you go above the tolerability limit, your design is not okay by definition. And you have to do something, which could be just not building the design, or if it is an existing building, you have to do something. And it might be very expensive to do something, but you have to. What is the justification for having a tolerability limit? Well, this is inconvenient. I said in the beginning, like, well, let's keep it objective and so on. Well, yes, when you calculate risks and so on, it's objective. The tolerability limit, the justification for having that is that we recognize that, for example, high-consequence events are not acceptable to society or to individual people, depending on what you're talking about. And same for high-frequency events, probably, and different combinations of that. We just recognize that there is some psychological aspect there, which is put into vulnerability limit. And this vulnerability limit actually allows you to benchmark your risk profile against this aggregated psychological effect. So no justification of economics or so on, as far as I am aware of. Surely, okay, if you have this building, it's a high-rise building. If you have this building and there is sprinkler control and this and that, but lots of active systems, but a typical example may be, there is no staircase. Because why should we need it? We don't need staircases. Just an elevator, which you drive with your Ferrari and you're being driven up to your penthouse. Staircase is a waste of square feet that you could sell. Yeah? Exactly. Which is a very fair point. If you do it purely on an economic term, I would not be surprised if you can find situations where indeed having no staircases or a very low number of staircases makes economic sense. But we say, ah, this is still not okay. And why not? Well, because in the extremely unlikely event, extremely unlikely, so unlikely that the monetary value becomes very low. But still, an extremely unlikely event that our active control measures, the many we have, who are great and managed and everything, if everything would fail for whatever reason, we do have a problem. And we cannot justify the day after that a couple of thousand people died. Yeah, there was no stay. So this is something beyond the tolerability that must be... Yeah, so that would be an example, very short and hypothetical, but it would be an example. That's at least to me, it's a justification, why would you always need a staircase? Because whatever happens, you always need a staircase because this is risk. If you think about risk, because risk is more fundamental than prescriptive guidance right different discussion maybe blowing up discussion here so risk is the reality so risk profile of the building why do we need staircases in every building well apparently because it's not tolerable not to have it and it doesn't matter if you can tell me that it's very expensive to have this staircase. That doesn't matter. We need a staircase. Otherwise, it's not tolerable. I guess the same case could be now brought into a flammable facade with cavity in a super tall building. Apparently, very interesting. Because if you talk about costs and benefits, what we don't do, as far as I'm aware of, but I mean, we're not taking things very holistic, right? And holistic, I mean, even beyond fire safety, some of those claddings, they might be actually very good from an environmental perspective. Not my expertise, so I don't know, but let's say hypothetically, it could be a real winner. And the likelihood of having a fire is very low and so on. So in the end, you could say, well, it's actually cost effective. Yeah, we should all go for claddings. But maybe we agree that it's not tolerable to have these kind of consequences. And I would then say, ah, tolerable relates to probabilities and consequences. Yes. So we have these kinds of consequences. So if you use this kind of cladding on a low-rise building where you say that the consequences are, for whatever reason, very low, then I see no point to be against it. This is a really good discussion because obviously I could ask you like, what is the total labor risk or who should define that? And we could be talking about hours on that. But I just like to leave it that you have this tool. You have the tool of risk. You have probabilities, you have consequences, you have some ways to map them out to see the bigger picture, and you have a tool to define at what point something is tolerable, at what point it's not. And then you apply this unbiased method to this unbiased collection of your scenarios, and you can really filter them out and see, like, case by case what's the case in there and and take engineering decisions based on that so wherever this limit lies which probably is the obligation of person responsible for setting whoever that is in your country politician architect firefighter whoever that may be. It's a tool that you can work with. And to be even stronger, and not everybody will like this, but I find it very relevant as a tool for thinking. You have tolerability limit and then you have to do cost-effectiveness and so on. Does that mean that you need to specify this limit and give numbers to it? Personally, no. There are a number of reasons for that. I say, okay, it's very difficult. We should decide and so on. That's all true. Also, setting a limit actually invites people to go as close as possible to it. I see no reason to have this kind of limit because you should actually stay away from it. It's thinking wise. It's just like, look, in my head, there is this limit. I should stay away from it. And then can I tell myself with my own judgment that I am clearly in a tolerable region? If I can do that, then from my perspective, I am fine. So what happens when you're just below the tolerability limit? What does the risk tools tell you? So the tolerability limit is a concept for thinking. It doesn't need to be quantified. I mean, some countries or legislations might want to quantify it. It doesn't need to be quantified. But in a situation where it's not quantified, what you're actually saying is that your risk is quite high and that you feel uncomfortable and that you are like, well, am I tolerable here? So this then pushes the engineer to say, well, actually, I should reduce the risk because I am not comfortable. And this is the concept. If your country has a strict limit, well, okay, then you could say you're in the Al Arab region now because you're underneath the liability limit and you have to look at cost-effectiveness. But when you're very close, and these discussions come up a lot. I might be jumping a little bit here, but people often bring up this very same comment, maybe with different words. They are, yeah, but if you're very close to the tolerability limit, and then how sure are you about your inputs? If your input is a bit different, maybe you're above the tolerability limit and so on. Yeah, these discussions make sense if your tolerability limit is really fixed. If this is really something you can be above or below, but if it is a concept where you say, above that, I'm not comfortable, this is not okay, and below that, okay, I'm fine, and I just need to check if I'm actually cost-effective here, then having the variation in your parameters doesn't matter so much anymore, because it's part of your evaluation there. Now I wanted to jump into something else. For me, the concept of risk, it was such a profound thing, because you could accommodate also things like failure probabilities, performance of your devices. How does the risk deal with it? I assume they are hidden within the scenarios that you investigate. But maybe you can tell me a bigger picture. How you would approach measuring that in your scenario. Like when I said about my smoke control system case in the shopping mall. But I may have a case where my one fan has failed. Or I may have a case where the smoke is not detected and it is delayed by some time. Which of these events has some probability? There's also a distribution in the fire size, because I just assume a design fire, which is, let's say, an agreed representation of some sort of very bad but still probable fire in that case. But I have no idea what it really will be. It will be a scatter of different amounts of heat, different amounts of smoke, production parameters. It's all distributions. So how the world of risk works with assumptions that are not just sharp one point thing, but distributions. There are a number of aspects there. And to some extent, it's a choice for the engineer and the choice i mean that you are building a model right you're building a model to model the risk of the building and you can do that in different ways so one way to go ahead if you have parameters with a continuous distribution like like your fire size potentially say okay five megawatts 5.1 6 6.2 so it's a continuous distribution then you can do repeated calculations if you're using calculation model and just sample from your input distributions and get a view on your output. Now this maybe or maybe not sounds easy. It's actually relatively difficult because if I say get a view on your output, if your output is a 3D view of how smoke is propagating, then what this means if you do repeated sampling is not so clear anymore. But then what is easy if you say, ah, how many minutes is my certain door available right okay so that you can do and say ah it's five minutes in this situation simulation 5.2 and that and you get your distribution of this time that its door is available but if it's a 3d smoke picture you don't have this so you you definitely lose some information there now i say it's model because you have the other part as well. You said about the small control system failing. Depends what you mean with failure. But if you say just it activates or it does not activate, in that case, you, for example, have two trees or two in your event tree. So then you jump into an event tree, put it that way, and say, okay, one event the smoke control system activates, one event the smoke control system does not activate. And you can add granularity to that if you want, but now you have in your CFD or whatever you're using, you have two different models now. You have one where the system is not active, and one where the system is active. And now if you want, you can now have even two Monte Carlo simulations or anything else inside the branches of your event tree so then for each of those scenarios they still take into account the uncertainty in your fire size or you can split it up into five discrete fire sizes and then what I can do is take if I know the combined probability of a certain branch of my events tree happening because i assume the probabilities are either known or number can be given to them so as i venture through my events tree i know this branch okay 30 this branch 70 in the branch of 30 another event is 50 50 so i have 2 times 15. Other branch. And so on. You can work out the individual probability of each of your final branches, the last branch. Then you can do some sort of engineering calculation to determine the consequence. And then you have points to feed your plot of probability consequence. And you can start seeing them as they align. consequence and you can start seeing them as they align maybe an event where nothing in my building works and the fire is a hundred times bigger than it should be it will give me a consequence of catastrophical failure but i will see okay the probability was like one to minus i don't know 12 so it would go so far into into the plot that we could never consider that, I guess. Are there events that are intolerable no matter their probability? That's something I wondered. To me, conceptually, yes. So you have your tolerability limit, and tolerability limit basically says events which are there or designs which have a risk profile which goes into an intolerable region, those designs are not acceptable. I do think, indeed, it is reasonable to cut off somewhere at a very, very low probability anything you represent just because it becomes a bit ridiculous to really say that you're calculating stuff up to such a precision. But on the other hand, yeah, this is the case about the staircase we talked about earlier, right? So because if your sprinkler system and you have a 24-7, 10-people management team and so on, so your buildings can be extremely safe, but still you're saying, well, we still need staircases. Okay. I guess the outcome is also like if your building has this point, then it probably should not be built. And that's the ultimate thing also to figure out, okay, if my building has a scenario that leads to a death of a thousand people, no matter my safety strategy, there is this chain of events that leads to this tragic consequence, maybe you either should redesign it completely or maybe not build it. Again, you are showing risk not as a mythical concept from the land of unicorns. It is a tool for engineers to use. I like that. Yeah, that's why I like this 2D visualization because this gives a lot of information. It's not easy to interpret always, but it gives you how often things happen and how severe they could get and the combinations of the two. and how severe they could get and the combinations of the two. If somebody gives you just a single number, which sometimes you can see, that they just combine different scenarios in a single number, this tells me personally not much, really. If, say, this is a metro station, and this metro station, the annual risk of death by fire is this number, like, okay, I don't know what this means now. Did you just lose 200 people in a very low event? Or are you talking about, what is this? So the 2D visual is very nice. One thing to maybe add in what we just said, without closing the topic, because I don't think it is closed. But when we're talking about these very high consequence events and things which are not acceptable no matter what and so on, we're getting very close. so that's my feeling, with something you had in one of the previous podcasts some time ago with KME, for example, maximum allowable damage. So with these things, I mean, I see, I feel, is a better word, that these things actually might match a lot. So it's not one or the other. That's what I'm trying to say. Yeah, cool, cool. Okay, we said that risk would be some sort of collection of probabilities and consequences. Probabilities, I feel, are not necessary very much to explain. I think every engineer should understand the concept of probability. But I wonder about the measures of consequences. So far, you've mentioned fatalities when we discussed the curves, and you mentioned there can be a fan curve, or people affected by the fire also, not necessarily fatalities, but people affected by the fire. I guess there could be a monetary analysis where you would just put a value in whatever currency you prefer on the damage. Definitely, yeah. How else would you measure the consequences? Or these are like the ultimate ones. Anything you want. And this is the thing, we don't do enough. You don't see that every day. I always work with FN curves, to be honest. I honestly don't think I have ever worked with anything else. But yet here opens a whole world of possibilities where you could map stuff in such a different way to gain a real understanding of a building. So, yeah. So, I should actually open up my own definition there somewhere. I actually don't have it fresh. So, I always like to say design should be socio-economically acceptable. And this is where we should start. Because people always jump into the traditional fire safety objectives, life safety, property protection, and so on, but miss things. And then in the end, some people add cultural heritage, because they feel that indeed, there are some cases which don't match the traditional ones, and so on. And the risk of doing it that way, I mean, choosing the traditional ones and then adding something which you think about, is that you don't take a broad approach and actually think what is important here. If you're having a tunnel, then it's very likely, I would say even extremely likely, that life safety is key, yes, but defining for a design is your business continuity. But defining for a design is your business continuity. So, yeah, if you never thought about it or if it didn't come up, then, well, yeah, it was not on your list. So if you think about it first, okay, why is this tunnel important? Okay, it's connecting two important parts of the city. Hopefully it comes up. If you have a museum and say, ah, yes, the evacuation is fine. We've lost all the antiques in it oh yeah everything is gone okay well probably that's not a great outcome yes i have iso in front of me like i said and for consequence ah these guys are good actually you know these guys these guys are good they say outcome or outcomes of an event expressed positively or negatively, quantitatively or qualitatively. That's a broad definition of a consequence, but like you said, it can be whatever you like it to be. Again, 42. What I'm not 100% sure of, but within the ISO framework, well, it is a framework, ISO, right? We have the higher engineering and then the sub-pairs, including structural engineering. But the higher engineering also refers to higher, more general standards. So this risk definition is probably not... From above, from above, okay. And so, you know, preparing for this discussion, Danny has sent me a very comprehensive list of questions to ask you, You know, preparing for this discussion, Danny has sent me a very comprehensive list of questions to ask you, which we're not even in one third. And it seems we'll run out of time. But let's try one item from that list. One that really is interesting to me, individual versus societal risk. And it also needs to be explained. I think it's also a fundamental concept. explained. I think it's also a fundamental concept. So how would you explain the difference between risk from the point of view of an individual and risk from the point of view of society, whatever society is? Okay, now we need to make a very clear distinction. But in the last question, you said point of view of society or point of view of... Okay, maybe point of view is not the best. well but i mean i can close that one relatively easily you can say societal is a public perspective but does society accept individual then it's a private perspective what does the private person accept so very straightforward in a way, society has, for example, prescriptive guidance, but society has somehow, maybe implicit, prescriptive accepts. Maybe there were some individuals who would have been happy to spend less money on fire safety in their building, and maybe some people want to go above, but this is their private choice, and society sets the minimum. So that's clear. Well, to me. So then if you say, okay, but that's the perspective. If you take like, okay, societal risk, individual risk, there's something different. So when we talked about FN diagrams, we were talking about what we often refer to societal risk. So the possibility of having multiple fatalities in a single event, and then with a traditional statement that multiple fatalities is not very much accepted. And so if you would have 100 people dying in a single event, this would be an outcry. It would change our legislation. Quite sure about that. If you would have 100 events with one person dying, probably don't change the legislation. The media would be bored after the fourth one and then would not even mention them anymore. Like we have with car accidents, right? Yeah. So that societal is there and it links them to tolerability limits and a tolerability limit is a limit to societal risk. What is important though, and it's very difficult, is that if you make an FN diagram, the FN diagram depends on the number of exposed people. So this is extremely inconvenient. So if you now say, ah, in the legislation or something, I'm going to put a limit on my tolerability. So I'm going to actually have a tolerability limit in legislation. Yeah, okay, how are you going to do this because if there are only 100 people working in the building then this is a natural limit on the number of people involved in the fire if you now have a much bigger site with thousands of people is it the same tolerability limit which applies it can't be because otherwise the other building is not safe so either way it's it's not obvious at all but if you could get said it mean, I like to think of it as concepts, really. If you say for a big building, thousands of people working there, the design is tolerable. Okay. So you're now saying that the frequency of having one person dying or exposed to fire or a hundred percent and so on, that's tolerable. You do an AL alarp evaluation or which can be just by expert judgment but implicitly you come to the conclusion that it's not cost effective to invest more okay fine you have now shown that on average for the average person there the risk is fine but you have not shown that it is fine for everybody and this is crucial do not forget this is then the individual risk because it is not unthinkable that in your big building, when you do all your evacuation simulations, if this is what you're doing, that the people who die in your simulations are always the same ones. So you're now having this FN diagram. Just one that died is okay, at this probability. Yeah, it's 5,000 people there. One person dies occasionally. Yes, but it's always the same room where people start where the people are where they die as in they start there and they never make make it to the exit so the individual risk for the people in that room for example mobility impaired people could also be related statement their individual risk will be too high so societal risk overall performance of the building individual risk saying like, and now looking at all the individuals, is it actually tolerable for everybody individually? Now, I understand this from the perspective of risk engineering. You may have an outcome that is acceptable from the bigger picture point of view, but potentially unacceptable from the individual point of view. If I have found a room where this individual risk is that high, I would put my IT in there. I don't know about you or the diversity, but I would have preferences there. That's engineering as well. Okay, good, good. Now I would like to take you into some private business. SFP is working on the new performance-based engineering guide. And I had the pleasure, privilege to be responsible for the hazards chapter in it and definition of hazards. So I would love to hear you. Now let's go into the process of risk engineering. How does one define their hazards and what hazards could be? Okay, this is really difficult. And I'm going to, whatever you say, I'm going to write it down in the standard now. I'm just kidding, don't worry. Because what I am regularly working with somehow is quantification of risk. So you said earlier before, for example, that my design fire and uncertainty in my design fire, uncertainty in phylo densities. Okay, this, and we propagate this, and we get a picture of the building. When you talk about hazards, you are now in an area which, to me, is very much about risk management, really, where you're now going to identify which hazards there are, what can be done to maybe eliminate some of those hazards. So it's a very different skill set. I mean, it's very important. So we talk, okay, what is hazard? We have the ISO document here also somewhere. Something with a potential to create negative consequences. It's an event or chain of events with potential to create harm. Something like that. It's not a precise definition, but more or less like that. So it might be possible to just eliminate some. So you have a process and an industrial plant, and there is a certain hazard there because they are using an open flame. Okay, we can eliminate this hazard by changing our process and removing the open flame. But within the risk evaluation, when I'm talking about, evaluating the risk of a building, going all the way there is something I have never done. That's a really big view. So again, as long as we stay to the simplest definition of risk, it's really accommodating. And now we went outside of it and it's now risk management, which is a process, which is a job to be done based on the fact that you have this unbiased measure of risk, which allows you to do that. Because then for hazards, hazards are very interesting because we have defined them that you need to identify all of them, but it's not the point where you judge whether this hazard makes sense or not whether is it high risk or low risk no no that's the like a set of inputs to your risk analysis and then through your risk analysis you will work out what they mean at the hazard definition you should not really evaluate because actually you can you can miss something and you need to apply the whole methodology to understand the consequence of an event that includes a particular hazard. So for us, it was a challenging thing to work around. And also you have to accommodate the fact that someone may miss a hazard. It's very difficult to understand all the hazards in your building. Yeah, so using the word all is maybe tricky. But there's always something that could have been missed, right? Exactly. By definition, I think it's impossible to identify all hazards. And then what is the value of looking into that? Well, the value is indeed that by thinking about hazards and identifying them, that you will find ways to eliminate some or to have mitigation measures and so on but it's much more about the process at least for me than it is about determining is my building now is my event curve of my building acceptable and let's start with looking at the hazard of having my washing machine having an electrical fault okay if you if you do that then the calculation is going to take a long time. We finally reached the point where you've touched the part of risk management that I think I like the most. And it's something that also when you've mentioned the episode with Jaime and David Lange about the maximal level of damage. And it was very process related. There is this framework this maybe you could even call it philosophy like if you do these things when defining risk for your building you will eventually come up with a pretty decent design of your building because going through the process and understanding these things through this type of measures makes you think about the solutions in a completely different way, eventually leading to a safer structure. So I think it's a value of risk engineering that is very difficult to quantify, like how much percent safer my building will be if I do risk analysis for it. I don't know, but it will be safer. It's something you cannot calculate. This subconscious feeling I have about this process that I really like. And that's also why I wanted to do an episode like this. So the whole concept is more approachable by more people, and maybe more people will be familiar enough or less intimidated to actually use it because the benefits are way, way beyond just putting a number to the consequences and probability of a scenario, right? Yeah, definitely. So on the process side, I fully agree. And then on the risk assessment, where you actually calculate a risk profile, I'm definitely not saying this should be done for every type of structure. It will probably be very rarely that the effort makes sense. But I hope that most fire engineers or people involved in fire safety realize or agree with me that there is this underlying risk profile for a building, which is its performance. And when you do one or five design fires and you calculate that, you are just testing it a bit and then making a judgment in the end that, yeah, based on those evaluations, the risk profile will be fine. But if you go a step further, which will not be necessary in many cases, but if you go a step further, you get a better picture. That's really what it is. It's not an alternative. It's just getting a better picture of the same thing. Okay, Ruben, thank you. Thank you so much for taking me into the approachable risk. And I really appreciate taking your time to have this difficult discussion. I mean, talking about fundamental concepts is sometimes the most difficult discussions there are. For the end, you can do whatever you want for your closing statement, but I would love how would you advertise? Did I ask you that again? Why do you tell your students to learn risk? Maybe I can say something very similar to what we said last time. It's fundamental. Yeah, you did. Now I remember. No, let's drop the students. Students are cool. Let's talk engineers. Why engineers who have never used risk concept in their life should take a while and learn a bit about it and appreciate it? Will it be useful to them? Because they are in the business of designing for risk. So no matter how you do it, if it is just by your opinion or by doing calculations, a number of set of them or many of them, you are in the business of evaluating the risk of a building and making sure it is acceptable. So this is your job, no matter how you do it. If you like it or not, if you know about it or not, it's your job. You should do it. If you know about it or not, it's your job. You should do it. Hey, Ruben, thank you so much for coming. And I guess we will have many more occasions to talk about risk in this podcast. I like this direction and I think we're doing something good here. Going into this journey and taking the listeners with us. So thanks a lot for coming. And yes, you're on, man. Yes, thanks a lot, Wojciech. And that's it. Thank you coming and yes you run man yes thanks a lot and that's it thank you ruben for this uh fantastic discussion it's uh so difficult to talk about the fundamental concepts and uh and ruben is is very brutal to the interviewer he always takes my questions and smashes it to atoms and answers one by one it's kind of stressful to interview like that but in the end the point of doing this is to learn and these are the moments where i learned the most so i guess for my audience you guys learn as much with me that's that's a great thing for sure if i had to pick one takeaway from these episodes for myself i guess it would be the difference between the societal risk and individual risk, but from this perspective of maybe someone is at higher risk, at disproportionate risk to the rest of the population of the building, that's a very interesting concept because I see here a potential to use this as a way to address the problems of disabled people, the problems of lack of accessibility for some, the problems with delivering a safety strategy that is inclusive for all in the building. That's a beautiful concept. And I think the tool, RISC, could be even better in this than I thought. So that is my takeaway. I wonder what your takeaway is. And if you enjoyed this episode, if you liked it, please let me know. I would love to learn if episodes like this are useful to you because I can make more of them, you know. And yeah, that would be it for today. Thank you all for the five-star ratings that are coming. I've heard that some are confused because you cannot find a five-star rating on the webpage and there's approximately 13% of the audience that listens confused because you cannot find a five-star rating on the webpage, and there's approximately 13% of the audience that listens to the podcast through my webpage, which I appreciate. That's the point of having a webpage. But if you want to relieve me of rating, you need to go to an app like Apple Podcasts or Spotify, and only there you can leave the reviews that are counted by the algorithms. The links to Apple Podcasts and Spotify are always under the episode descriptions. So there's like one click away to get into the app and then you can give me the five star rating if you really want to do that. And yeah, you actually do. Thank you very much for them. So thank you very much for joining me here this Wednesday and looking forward to having you here next Wednesday. See you. Bye. This was the Fire Science Show. Thank you for listening and see you soon.